{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DataCamp - Data Scientist Career Track (Python)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Merging DataFrames with pandas                 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = \"C:/Users/Utilizador/Dropbox/Python/ficheiros/DataCamp/DataCamp - Merging DataFrames with pandas/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##    CHAPTER 1  - Preparing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercício 1 - Reading multiple data files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vídeo\n",
    "#Reading multiple data files\n",
    "\n",
    "#Tools for pandas data import:\n",
    "#pd.read_csv() for CSV files\n",
    "#pd.read_excel()\n",
    "#pd.read_html()\n",
    "#pd.read_json()\n",
    "\n",
    "# Using a loop\n",
    "filenames = [data_folder + 'sales-jan-2015.csv', data_folder + 'sales-feb-2015.csv']\n",
    "dataframes = []\n",
    "for f in filenames:\n",
    "    dataframes.append(pd.read_csv(f))\n",
    "\n",
    "# Using a comprehension\n",
    "filenames = [data_folder + 'sales-jan-2015.csv', data_folder + 'sales-feb-2015.csv']\n",
    "dataframes = [pd.read_csv(f) for f in filenames]\n",
    "\n",
    "# Using glob\n",
    "from glob import glob\n",
    "filenames = glob(data_folder + 'sales*.csv')\n",
    "dataframes = [pd.read_csv(f) for f in filenames]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercício 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   NOC         Country   Total\n",
      "0  USA   United States  2088.0\n",
      "1  URS    Soviet Union   838.0\n",
      "2  GBR  United Kingdom   498.0\n",
      "3  FRA          France   378.0\n",
      "4  GER         Germany   407.0\n"
     ]
    }
   ],
   "source": [
    "# Reading DataFrames from multiple files\n",
    "\n",
    "# Read 'Bronze.csv' into a DataFrame: bronze\n",
    "bronze = pd.read_csv(data_folder + \"Bronze.csv\")\n",
    "\n",
    "# Read 'Silver.csv' into a DataFrame: silver\n",
    "silver = pd.read_csv(data_folder + \"Silver.csv\")\n",
    "\n",
    "# Read 'Gold.csv' into a DataFrame: gold\n",
    "gold = pd.read_csv(data_folder + \"Gold.csv\")\n",
    "\n",
    "# Print the first five rows of gold\n",
    "print(gold.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercício 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   NOC         Country   Total\n",
      "0  USA   United States  2088.0\n",
      "1  URS    Soviet Union   838.0\n",
      "2  GBR  United Kingdom   498.0\n",
      "3  FRA          France   378.0\n",
      "4  GER         Germany   407.0\n"
     ]
    }
   ],
   "source": [
    "# Reading DataFrames from multiple files in a loop\n",
    "\n",
    "# Create the list of file names: filenames\n",
    "filenames = [data_folder + 'Gold.csv', data_folder + 'Silver.csv', data_folder + 'Bronze.csv']\n",
    "\n",
    "# Create the list of three DataFrames: dataframes\n",
    "dataframes = []\n",
    "for filename in filenames:\n",
    "    dataframes.append(pd.read_csv(filename))\n",
    "\n",
    "# Print top 5 rows of 1st DataFrame in dataframes\n",
    "print(dataframes[0].head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercício 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   NOC         Country    Gold  Silver  Bronze\n",
      "0  USA   United States  2088.0  1195.0  1052.0\n",
      "1  URS    Soviet Union   838.0   627.0   584.0\n",
      "2  GBR  United Kingdom   498.0   591.0   505.0\n",
      "3  FRA          France   378.0   461.0   475.0\n",
      "4  GER         Germany   407.0   350.0   454.0\n"
     ]
    }
   ],
   "source": [
    "# Combining DataFrames from multiple data files (clumsy method)\n",
    "\n",
    "# combine the three DataFrames from earlier exercises - gold, silver, & bronze - into a single DataFrame called medals...\n",
    "\n",
    "# Make a copy of gold: medals\n",
    "medals = gold.copy()\n",
    "\n",
    "# Create list of new column labels (nomes do ficheiro 'gold.csv' subst 'Gold' por 'Total'): new_labels\n",
    "new_labels = ['NOC', 'Country', 'Gold']\n",
    "\n",
    "# Rename the columns of medals using new_labels\n",
    "medals.columns = new_labels\n",
    "\n",
    "# Add columns 'Silver' & 'Bronze' to medals\n",
    "medals['Silver'] = silver['Total']\n",
    "medals['Bronze'] = bronze['Total']\n",
    "\n",
    "# Print the head of medals\n",
    "print(medals.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercício 5 - Reindexing DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't find program: 'false'\n"
     ]
    }
   ],
   "source": [
    "%%script false\n",
    "#vídeo\n",
    "# Reindexing DataFrames\n",
    "\n",
    "# “Indexes” vs. “Indices”\n",
    "#  ● indices: many index labels within Index data structures   <-----------\n",
    "#  ● indexes: many pandas Index data structures                <-----------\n",
    "\n",
    "w_mean = pd.read_csv('quarterly_mean_temp.csv', index_col='Month')\n",
    "w_max = pd.read_csv('quarterly_max_temp.csv', index_col='Month')\n",
    "\n",
    "# Examining the data --> o index de w_mean está por ordem alfabética (Apr, Jan, Jul, Oct), o do w_max não (Jan, Apr, Jul, Oct)\n",
    "\n",
    "# .reindex()  \n",
    "ordered = ['Jan', 'Apr', 'Jul', 'Oct']\n",
    "w_mean2 = w_mean.reindex(ordered)       # o index de w_mean2 já aparece pela ordem dita\n",
    "\n",
    "# .sort_index()\n",
    "w_mean2.sort_index()  # volta ao inicial\n",
    "\n",
    "# Reindex from a DataFrame Index\n",
    "w_mean.reindex(w_max.index)  # põe o index do w_mean igual ao do w_max (Jan, Apr, Jul, Oct)\n",
    "\n",
    "# Reindexing with missing labels\n",
    "w_mean3 = w_mean.reindex(['Jan', 'Apr', 'Dec'])   # o Indice 'Dec' aparece com valor NaN\n",
    "\n",
    "w_max.reindex(w_mean3.index)   # fica com os Indices ('Jan', 'Apr', 'Dec') e em 'Dec' NaN também, por isso\n",
    "\n",
    "w_max.reindex(w_mean3.index).dropna()  # sai o Indice 'Dec'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercício 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't find program: 'false'\n"
     ]
    }
   ],
   "source": [
    "%%script false\n",
    "# Sorting DataFrame with the Index & columns\n",
    "\n",
    "# Read 'monthly_max_temp.csv' into a DataFrame: weather1\n",
    "weather1 = pd.read_csv('monthly_max_temp.csv', index_col='Month')\n",
    "\n",
    "# Print the head of weather1\n",
    "print(weather1.head())\n",
    "\n",
    "# Sort the index of weather1 in alphabetical order: weather2\n",
    "weather2 = weather1.sort_index()\n",
    "\n",
    "# Sort the index of weather1 in reverse alphabetical order: weather3\n",
    "weather3 = weather1.sort_index(ascending=False)\n",
    "\n",
    "# Sort weather1 numerically using the values of 'Max TemperatureF': weather4\n",
    "weather4 = weather1.sort_values('Max TemperatureF')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercício 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't find program: 'false'\n"
     ]
    }
   ],
   "source": [
    "%%script false\n",
    "# Reindexing DataFrame from a list\n",
    "\n",
    "year = ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec']\n",
    "\n",
    "# Reindex weather1 using the list year: weather2\n",
    "weather2 =  weather1.reindex(year)\n",
    "\n",
    "# Print weather2\n",
    "print(weather2)\n",
    "\n",
    "# Reindex weather1 using the list year with forward-fill: weather3\n",
    "weather3 = weather1.reindex(year).ffill()             # preenche os NaN de acordo com o valor imediatamente anterior\n",
    "\n",
    "# Print weather3\n",
    "print(weather3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercício 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19454, 3)\n",
      "(1934, 3)\n",
      "\n",
      "(1934, 3)\n",
      "(1934, 3)\n"
     ]
    }
   ],
   "source": [
    "# Reindexing using another DataFrame Index\n",
    "\n",
    "names_1881 = pd.read_csv(data_folder + \"names1881.csv\")\n",
    "names_1981 = pd.read_csv(data_folder + \"names1981.csv\")\n",
    "\n",
    "print(names_1981.shape)\n",
    "print(names_1881.shape)\n",
    "print(\"\")\n",
    "\n",
    "# Reindex names_1981 with index of names_1881: common_names\n",
    "common_names = names_1981.reindex(names_1881.index)\n",
    "\n",
    "# Print shape of common_names\n",
    "print(common_names.shape)     # (1934, 3), ok\n",
    "\n",
    "# Drop rows with null counts: common_names\n",
    "common_names = common_names.dropna() # ??\n",
    "\n",
    "# Print shape of new common_names\n",
    "print(common_names.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercício 9 - Arithmetic with Series & DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date\n",
      "2013-07-01    0.4572\n",
      "2013-07-02    0.3556\n",
      "2013-07-03    0.0000\n",
      "2013-07-04    0.6350\n",
      "2013-07-05    0.0508\n",
      "2013-07-06    0.1524\n",
      "2013-07-07    0.2540\n",
      "Name: PrecipitationIn, dtype: float64\n",
      "======================================================================\n",
      "            Min TemperatureF  Max TemperatureF\n",
      "Date                                          \n",
      "2013-07-01          0.916667          1.097222\n",
      "2013-07-02          0.891892          1.135135\n",
      "2013-07-03          0.910256          1.102564\n",
      "2013-07-04          0.909091          1.116883\n",
      "2013-07-05          0.907895          1.131579\n",
      "2013-07-06          0.897436          1.141026\n",
      "2013-07-07          0.972222          1.069444\n",
      "======================================================================\n",
      "Date\n",
      "2013-07-01         NaN\n",
      "2013-07-02    2.777778\n",
      "2013-07-03    5.405405\n",
      "2013-07-04   -1.282051\n",
      "2013-07-05   -1.298701\n",
      "2013-07-06    2.631579\n",
      "2013-07-07   -7.692308\n",
      "Name: Mean TemperatureF, dtype: float64\n",
      "======================================================================\n",
      "======================================================================\n",
      "      NOC                       Country   Total\n",
      "0  USAUSA    United StatesUnited States  2247.0\n",
      "1  URSURS      Soviet UnionSoviet Union  1211.0\n",
      "2  GBRGBR  United KingdomUnited Kingdom  1096.0\n",
      "3  FRAFRA                  FranceFrance   936.0\n",
      "4  GERGER                GermanyGermany   804.0\n",
      "======================================================================\n",
      "      NOC                       Country   Total\n",
      "0  USAUSA    United StatesUnited States  2247.0\n",
      "1  URSURS      Soviet UnionSoviet Union  1211.0\n",
      "2  GBRGBR  United KingdomUnited Kingdom  1096.0\n",
      "3  FRAFRA                  FranceFrance   936.0\n",
      "4  GERGER                GermanyGermany   804.0\n",
      "======================================================================\n",
      "      NOC                       Country   Total\n",
      "0  USAUSA    United StatesUnited States  2247.0\n",
      "1  URSURS      Soviet UnionSoviet Union  1211.0\n",
      "2  GBRGBR  United KingdomUnited Kingdom  1096.0\n",
      "3  FRAFRA                  FranceFrance   936.0\n",
      "4  GERGER                GermanyGermany   804.0\n",
      "======================================================================\n",
      "           NOC                                            Country   Total\n",
      "0    USAUSAUSA            United StatesUnited StatesUnited States  4335.0\n",
      "1    URSURSURS               Soviet UnionSoviet UnionSoviet Union  2049.0\n",
      "2    GBRGBRGBR         United KingdomUnited KingdomUnited Kingdom  1594.0\n",
      "3    FRAFRAFRA                                 FranceFranceFrance  1314.0\n",
      "4    GERGERGER                              GermanyGermanyGermany  1211.0\n",
      "5    AUSAUSAUS                        AustraliaAustraliaAustralia  1075.0\n",
      "6    ITAITAITA                                    ItalyItalyItaly  1228.0\n",
      "7    HUNHUNHUN                              HungaryHungaryHungary  1053.0\n",
      "8    SWESWESWE                                 SwedenSwedenSweden  1021.0\n",
      "9    NEDNEDNED                  NetherlandsNetherlandsNetherlands   782.0\n",
      "10   ROUROUROU                              RomaniaRomaniaRomania   624.0\n",
      "11   JPNJPNJPN                                    JapanJapanJapan   704.0\n",
      "12   RUSRUSRUS                                 RussiaRussiaRussia   638.0\n",
      "13   CANCANCAN                                 CanadaCanadaCanada   592.0\n",
      "14   GDRGDRGDR               East GermanyEast GermanyEast Germany   825.0\n",
      "15   POLPOLPOL                                 PolandPolandPoland   499.0\n",
      "16   FINFINFIN                              FinlandFinlandFinland   451.0\n",
      "17   CHNCHNCHN                                    ChinaChinaChina   679.0\n",
      "18   FRGFRGFRG               West GermanyWest GermanyWest Germany   490.0\n",
      "19   BRABRABRA                                 BrazilBrazilBrazil   372.0\n",
      "20   DENDENDEN                              DenmarkDenmarkDenmark   491.0\n",
      "21   BELBELBEL                              BelgiumBelgiumBelgium   408.0\n",
      "22   NORNORNOR                                 NorwayNorwayNorway   537.0\n",
      "23   SUISUISUI                  SwitzerlandSwitzerlandSwitzerland   376.0\n",
      "24   BULBULBUL                           BulgariaBulgariaBulgaria   331.0\n",
      "25   KORKORKOR               Korea, SouthKorea, SouthKorea, South   466.0\n",
      "26   YUGYUGYUG                     YugoslaviaYugoslaviaYugoslavia   435.0\n",
      "27   CUBCUBCUB                                       CubaCubaCuba   395.0\n",
      "28   TCHTCHTCH         CzechoslovakiaCzechoslovakiaCzechoslovakia   329.0\n",
      "29   ESPESPESP                                    SpainSpainSpain   377.0\n",
      "..         ...                                                ...     ...\n",
      "108  BARBARBAR                           BarbadosBarbadosBarbados     NaN\n",
      "109  BERBERBER                           Bermuda*Bermuda*Bermuda*     NaN\n",
      "110  DJIDJIDJI                           DjiboutiDjiboutiDjibouti     NaN\n",
      "111  ERIERIERI                              EritreaEritreaEritrea     NaN\n",
      "112  GUYGUYGUY                                 GuyanaGuyanaGuyana     NaN\n",
      "113  IRQIRQIRQ                                       IraqIraqIraq     NaN\n",
      "114  KUWKUWKUW                                 KuwaitKuwaitKuwait     NaN\n",
      "115  MKDMKDMKD                        MacedoniaMacedoniaMacedonia     NaN\n",
      "116  MRIMRIMRI                        MauritiusMauritiusMauritius     NaN\n",
      "117  NIGNIGNIG                                    NigerNigerNiger     NaN\n",
      "118  TOGTOGTOG                                       TogoTogoTogo     NaN\n",
      "119  PARPARPAR                           ParaguayParaguayParaguay     NaN\n",
      "120  PERPERPER                                       PeruPeruPeru     NaN\n",
      "121  SCGSCGSCG                                 SerbiaSerbiaSerbia     NaN\n",
      "122  NAMNAMNAM                              NamibiaNamibiaNamibia     NaN\n",
      "123  SINSINSIN                        SingaporeSingaporeSingapore     NaN\n",
      "124  HKGHKGHKG                     Hong Kong*Hong Kong*Hong Kong*     NaN\n",
      "125  SRISRISRI                        Sri LankaSri LankaSri Lanka     NaN\n",
      "126  TANTANTAN                           TanzaniaTanzaniaTanzania     NaN\n",
      "127  VIEVIEVIE                              VietnamVietnamVietnam     NaN\n",
      "128  ECUECUECU                              EcuadorEcuadorEcuador     NaN\n",
      "129  LUXLUXLUX                     LuxembourgLuxembourgLuxembourg     NaN\n",
      "130  AHOAHOAHO  Netherlands Antilles*Netherlands Antilles*Neth...     NaN\n",
      "131  CIVCIVCIV            Cote d'IvoireCote d'IvoireCote d'Ivoire     NaN\n",
      "132  ISVISVISV      Virgin Islands*Virgin Islands*Virgin Islands*     NaN\n",
      "133  SENSENSEN                              SenegalSenegalSenegal     NaN\n",
      "134  SUDSUDSUD                                    SudanSudanSudan     NaN\n",
      "135  TGATGATGA                                    TongaTongaTonga     NaN\n",
      "136  BDIBDIBDI                              BurundiBurundiBurundi     NaN\n",
      "137  UAEUAEUAE  United Arab EmiratesUnited Arab EmiratesUnited...     NaN\n",
      "\n",
      "[138 rows x 3 columns]\n",
      "======================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Utilizador\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py:3772: RuntimeWarning: Cannot compare type 'Timestamp' with type 'str', sort order is undefined for incomparable objects\n",
      "  return this.join(other, how=how, return_indexers=return_indexers)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NOC</th>\n",
       "      <th>Country</th>\n",
       "      <th>Total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>USAUSAUSA</td>\n",
       "      <td>United StatesUnited StatesUnited States</td>\n",
       "      <td>4335.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>URSURSURS</td>\n",
       "      <td>Soviet UnionSoviet UnionSoviet Union</td>\n",
       "      <td>2049.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GBRGBRGBR</td>\n",
       "      <td>United KingdomUnited KingdomUnited Kingdom</td>\n",
       "      <td>1594.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FRAFRAFRA</td>\n",
       "      <td>FranceFranceFrance</td>\n",
       "      <td>1314.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GERGERGER</td>\n",
       "      <td>GermanyGermanyGermany</td>\n",
       "      <td>1211.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>AUSAUSAUS</td>\n",
       "      <td>AustraliaAustraliaAustralia</td>\n",
       "      <td>1075.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ITAITAITA</td>\n",
       "      <td>ItalyItalyItaly</td>\n",
       "      <td>1228.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>HUNHUNHUN</td>\n",
       "      <td>HungaryHungaryHungary</td>\n",
       "      <td>1053.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>SWESWESWE</td>\n",
       "      <td>SwedenSwedenSweden</td>\n",
       "      <td>1021.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>NEDNEDNED</td>\n",
       "      <td>NetherlandsNetherlandsNetherlands</td>\n",
       "      <td>782.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ROUROUROU</td>\n",
       "      <td>RomaniaRomaniaRomania</td>\n",
       "      <td>624.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>JPNJPNJPN</td>\n",
       "      <td>JapanJapanJapan</td>\n",
       "      <td>704.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>RUSRUSRUS</td>\n",
       "      <td>RussiaRussiaRussia</td>\n",
       "      <td>638.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>CANCANCAN</td>\n",
       "      <td>CanadaCanadaCanada</td>\n",
       "      <td>592.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>GDRGDRGDR</td>\n",
       "      <td>East GermanyEast GermanyEast Germany</td>\n",
       "      <td>825.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>POLPOLPOL</td>\n",
       "      <td>PolandPolandPoland</td>\n",
       "      <td>499.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>FINFINFIN</td>\n",
       "      <td>FinlandFinlandFinland</td>\n",
       "      <td>451.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>CHNCHNCHN</td>\n",
       "      <td>ChinaChinaChina</td>\n",
       "      <td>679.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>FRGFRGFRG</td>\n",
       "      <td>West GermanyWest GermanyWest Germany</td>\n",
       "      <td>490.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>BRABRABRA</td>\n",
       "      <td>BrazilBrazilBrazil</td>\n",
       "      <td>372.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>DENDENDEN</td>\n",
       "      <td>DenmarkDenmarkDenmark</td>\n",
       "      <td>491.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>BELBELBEL</td>\n",
       "      <td>BelgiumBelgiumBelgium</td>\n",
       "      <td>408.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>NORNORNOR</td>\n",
       "      <td>NorwayNorwayNorway</td>\n",
       "      <td>537.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>SUISUISUI</td>\n",
       "      <td>SwitzerlandSwitzerlandSwitzerland</td>\n",
       "      <td>376.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>BULBULBUL</td>\n",
       "      <td>BulgariaBulgariaBulgaria</td>\n",
       "      <td>331.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>KORKORKOR</td>\n",
       "      <td>Korea, SouthKorea, SouthKorea, South</td>\n",
       "      <td>466.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>YUGYUGYUG</td>\n",
       "      <td>YugoslaviaYugoslaviaYugoslavia</td>\n",
       "      <td>435.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>CUBCUBCUB</td>\n",
       "      <td>CubaCubaCuba</td>\n",
       "      <td>395.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>TCHTCHTCH</td>\n",
       "      <td>CzechoslovakiaCzechoslovakiaCzechoslovakia</td>\n",
       "      <td>329.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>ESPESPESP</td>\n",
       "      <td>SpainSpainSpain</td>\n",
       "      <td>377.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>BARBARBAR</td>\n",
       "      <td>BarbadosBarbadosBarbados</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>BERBERBER</td>\n",
       "      <td>Bermuda*Bermuda*Bermuda*</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>DJIDJIDJI</td>\n",
       "      <td>DjiboutiDjiboutiDjibouti</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>ERIERIERI</td>\n",
       "      <td>EritreaEritreaEritrea</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>GUYGUYGUY</td>\n",
       "      <td>GuyanaGuyanaGuyana</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>IRQIRQIRQ</td>\n",
       "      <td>IraqIraqIraq</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>KUWKUWKUW</td>\n",
       "      <td>KuwaitKuwaitKuwait</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>MKDMKDMKD</td>\n",
       "      <td>MacedoniaMacedoniaMacedonia</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>MRIMRIMRI</td>\n",
       "      <td>MauritiusMauritiusMauritius</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>NIGNIGNIG</td>\n",
       "      <td>NigerNigerNiger</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>TOGTOGTOG</td>\n",
       "      <td>TogoTogoTogo</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>PARPARPAR</td>\n",
       "      <td>ParaguayParaguayParaguay</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>PERPERPER</td>\n",
       "      <td>PeruPeruPeru</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>SCGSCGSCG</td>\n",
       "      <td>SerbiaSerbiaSerbia</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>NAMNAMNAM</td>\n",
       "      <td>NamibiaNamibiaNamibia</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>SINSINSIN</td>\n",
       "      <td>SingaporeSingaporeSingapore</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>124</th>\n",
       "      <td>HKGHKGHKG</td>\n",
       "      <td>Hong Kong*Hong Kong*Hong Kong*</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>SRISRISRI</td>\n",
       "      <td>Sri LankaSri LankaSri Lanka</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>126</th>\n",
       "      <td>TANTANTAN</td>\n",
       "      <td>TanzaniaTanzaniaTanzania</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127</th>\n",
       "      <td>VIEVIEVIE</td>\n",
       "      <td>VietnamVietnamVietnam</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>128</th>\n",
       "      <td>ECUECUECU</td>\n",
       "      <td>EcuadorEcuadorEcuador</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>129</th>\n",
       "      <td>LUXLUXLUX</td>\n",
       "      <td>LuxembourgLuxembourgLuxembourg</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>AHOAHOAHO</td>\n",
       "      <td>Netherlands Antilles*Netherlands Antilles*Neth...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>CIVCIVCIV</td>\n",
       "      <td>Cote d'IvoireCote d'IvoireCote d'Ivoire</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>ISVISVISV</td>\n",
       "      <td>Virgin Islands*Virgin Islands*Virgin Islands*</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>133</th>\n",
       "      <td>SENSENSEN</td>\n",
       "      <td>SenegalSenegalSenegal</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>134</th>\n",
       "      <td>SUDSUDSUD</td>\n",
       "      <td>SudanSudanSudan</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>TGATGATGA</td>\n",
       "      <td>TongaTongaTonga</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>BDIBDIBDI</td>\n",
       "      <td>BurundiBurundiBurundi</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137</th>\n",
       "      <td>UAEUAEUAE</td>\n",
       "      <td>United Arab EmiratesUnited Arab EmiratesUnited...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>138 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           NOC                                            Country   Total\n",
       "0    USAUSAUSA            United StatesUnited StatesUnited States  4335.0\n",
       "1    URSURSURS               Soviet UnionSoviet UnionSoviet Union  2049.0\n",
       "2    GBRGBRGBR         United KingdomUnited KingdomUnited Kingdom  1594.0\n",
       "3    FRAFRAFRA                                 FranceFranceFrance  1314.0\n",
       "4    GERGERGER                              GermanyGermanyGermany  1211.0\n",
       "5    AUSAUSAUS                        AustraliaAustraliaAustralia  1075.0\n",
       "6    ITAITAITA                                    ItalyItalyItaly  1228.0\n",
       "7    HUNHUNHUN                              HungaryHungaryHungary  1053.0\n",
       "8    SWESWESWE                                 SwedenSwedenSweden  1021.0\n",
       "9    NEDNEDNED                  NetherlandsNetherlandsNetherlands   782.0\n",
       "10   ROUROUROU                              RomaniaRomaniaRomania   624.0\n",
       "11   JPNJPNJPN                                    JapanJapanJapan   704.0\n",
       "12   RUSRUSRUS                                 RussiaRussiaRussia   638.0\n",
       "13   CANCANCAN                                 CanadaCanadaCanada   592.0\n",
       "14   GDRGDRGDR               East GermanyEast GermanyEast Germany   825.0\n",
       "15   POLPOLPOL                                 PolandPolandPoland   499.0\n",
       "16   FINFINFIN                              FinlandFinlandFinland   451.0\n",
       "17   CHNCHNCHN                                    ChinaChinaChina   679.0\n",
       "18   FRGFRGFRG               West GermanyWest GermanyWest Germany   490.0\n",
       "19   BRABRABRA                                 BrazilBrazilBrazil   372.0\n",
       "20   DENDENDEN                              DenmarkDenmarkDenmark   491.0\n",
       "21   BELBELBEL                              BelgiumBelgiumBelgium   408.0\n",
       "22   NORNORNOR                                 NorwayNorwayNorway   537.0\n",
       "23   SUISUISUI                  SwitzerlandSwitzerlandSwitzerland   376.0\n",
       "24   BULBULBUL                           BulgariaBulgariaBulgaria   331.0\n",
       "25   KORKORKOR               Korea, SouthKorea, SouthKorea, South   466.0\n",
       "26   YUGYUGYUG                     YugoslaviaYugoslaviaYugoslavia   435.0\n",
       "27   CUBCUBCUB                                       CubaCubaCuba   395.0\n",
       "28   TCHTCHTCH         CzechoslovakiaCzechoslovakiaCzechoslovakia   329.0\n",
       "29   ESPESPESP                                    SpainSpainSpain   377.0\n",
       "..         ...                                                ...     ...\n",
       "108  BARBARBAR                           BarbadosBarbadosBarbados     1.0\n",
       "109  BERBERBER                           Bermuda*Bermuda*Bermuda*     1.0\n",
       "110  DJIDJIDJI                           DjiboutiDjiboutiDjibouti     1.0\n",
       "111  ERIERIERI                              EritreaEritreaEritrea     1.0\n",
       "112  GUYGUYGUY                                 GuyanaGuyanaGuyana     1.0\n",
       "113  IRQIRQIRQ                                       IraqIraqIraq     1.0\n",
       "114  KUWKUWKUW                                 KuwaitKuwaitKuwait     1.0\n",
       "115  MKDMKDMKD                        MacedoniaMacedoniaMacedonia     1.0\n",
       "116  MRIMRIMRI                        MauritiusMauritiusMauritius     1.0\n",
       "117  NIGNIGNIG                                    NigerNigerNiger     1.0\n",
       "118  TOGTOGTOG                                       TogoTogoTogo     1.0\n",
       "119  PARPARPAR                           ParaguayParaguayParaguay    17.0\n",
       "120  PERPERPER                                       PeruPeruPeru    15.0\n",
       "121  SCGSCGSCG                                 SerbiaSerbiaSerbia    14.0\n",
       "122  NAMNAMNAM                              NamibiaNamibiaNamibia     4.0\n",
       "123  SINSINSIN                        SingaporeSingaporeSingapore     4.0\n",
       "124  HKGHKGHKG                     Hong Kong*Hong Kong*Hong Kong*     3.0\n",
       "125  SRISRISRI                        Sri LankaSri LankaSri Lanka     2.0\n",
       "126  TANTANTAN                           TanzaniaTanzaniaTanzania     2.0\n",
       "127  VIEVIEVIE                              VietnamVietnamVietnam     2.0\n",
       "128  ECUECUECU                              EcuadorEcuadorEcuador     2.0\n",
       "129  LUXLUXLUX                     LuxembourgLuxembourgLuxembourg     2.0\n",
       "130  AHOAHOAHO  Netherlands Antilles*Netherlands Antilles*Neth...     1.0\n",
       "131  CIVCIVCIV            Cote d'IvoireCote d'IvoireCote d'Ivoire     1.0\n",
       "132  ISVISVISV      Virgin Islands*Virgin Islands*Virgin Islands*     1.0\n",
       "133  SENSENSEN                              SenegalSenegalSenegal     1.0\n",
       "134  SUDSUDSUD                                    SudanSudanSudan     1.0\n",
       "135  TGATGATGA                                    TongaTongaTonga     1.0\n",
       "136  BDIBDIBDI                              BurundiBurundiBurundi     1.0\n",
       "137  UAEUAEUAE  United Arab EmiratesUnited Arab EmiratesUnited...     1.0\n",
       "\n",
       "[138 rows x 3 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#vídeo\n",
    "#Arithmetic with Series & DataFrames\n",
    "\n",
    "weather = pd.read_csv(data_folder + \"pittsburgh2013.csv\", index_col='Date', parse_dates=True)\n",
    "weather.loc['2013-7-1':'2013-7-7', 'PrecipitationIn']\n",
    "\n",
    "# Scalar multiplication\n",
    "print(weather.loc['2013-07-01':'2013-07-07', 'PrecipitationIn'] * 2.54)      # faz com todas as colunas sem ser o index, 1 neste caso\n",
    "\n",
    "print(\"======================================================================\")\n",
    "\n",
    "week1_range = weather.loc['2013-07-01':'2013-07-07', ['Min TemperatureF', 'Max TemperatureF']]\n",
    "week1_mean = weather.loc['2013-07-01':'2013-07-07', 'Mean TemperatureF']\n",
    "\n",
    "week1_range / week1_mean \n",
    "   # the column labels don't match:\n",
    "   # RuntimeWarning: Cannot compare type 'Timestamp' with type 'str', sort order is undefined for incomparable objects\n",
    "    \n",
    "# Divide \n",
    "print(week1_range.divide(week1_mean, axis='rows'))  #assim já dá\n",
    "\n",
    "print(\"======================================================================\")\n",
    "\n",
    "# Percentage changes\n",
    "print(week1_mean.pct_change() * 100)\n",
    "\n",
    "print(\"======================================================================\")\n",
    "print(\"======================================================================\")\n",
    "\n",
    "# .csv Olympic medals\n",
    "bronze\n",
    "silver\n",
    "gold\n",
    "\n",
    "print((bronze + silver).head())        # se não houver linhas compatíveis aparece NaN\n",
    "\n",
    "print(\"======================================================================\")\n",
    "\n",
    "print(bronze.add(silver).head())           #é o mesmo que o anterior, mas é mais flexível porque dá para tirar os NaN\n",
    "\n",
    "print(\"======================================================================\")\n",
    "\n",
    "print(bronze.add(silver, fill_value=0).head())\n",
    "\n",
    "print(\"======================================================================\")\n",
    "\n",
    "print(bronze + silver + gold)\n",
    "\n",
    "print(\"======================================================================\")\n",
    "\n",
    "# Chaining .add()\n",
    "bronze.add(silver, fill_value=0).add(gold, fill_value=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercício 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding unaligned DataFrames\n",
    "\n",
    "# resposta: a soma de 2 colunas de df diferentes dá a reunião das duas, com NaN's se for o caso"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercício 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Min TemperatureC  Mean TemperatureC  Max TemperatureC\n",
      "Date                                                             \n",
      "2013-01-01         -6.111111          -2.222222          0.000000\n",
      "2013-01-02         -8.333333          -6.111111         -3.888889\n",
      "2013-01-03         -8.888889          -4.444444          0.000000\n",
      "2013-01-04         -2.777778          -2.222222         -1.111111\n",
      "2013-01-05         -3.888889          -1.111111          1.111111\n"
     ]
    }
   ],
   "source": [
    "# Broadcasting in arithmetic formulas\n",
    "\n",
    "# Extract selected columns from weather as new DataFrame: temps_f\n",
    "temps_f = weather[['Min TemperatureF', 'Mean TemperatureF', 'Max TemperatureF']]\n",
    "\n",
    "# Convert temps_f to celsius: temps_c\n",
    "temps_c = (temps_f - 32)*5/9\n",
    "\n",
    "# Rename 'F' in column names with 'C': temps_c.columns\n",
    "temps_c.columns = temps_c.columns.str.replace('F', 'C')\n",
    "\n",
    "# Print first 5 rows of temps_c\n",
    "print(temps_c.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercício 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              VALUE\n",
      "DATE               \n",
      "2014-07-01  17569.4\n",
      "2014-10-01  17692.2\n",
      "2015-01-01  17783.6\n",
      "2015-04-01  17998.3\n",
      "2015-07-01  18141.9\n",
      "2015-10-01  18222.8\n",
      "2016-01-01  18281.6\n",
      "2016-04-01  18436.5\n",
      "              VALUE\n",
      "DATE               \n",
      "2008-12-31  14549.9\n",
      "2009-12-31  14566.5\n",
      "2010-12-31  15230.2\n",
      "2011-12-31  15785.3\n",
      "2012-12-31  16297.3\n",
      "2013-12-31  16999.9\n",
      "2014-12-31  17692.2\n",
      "2015-12-31  18222.8\n",
      "2016-12-31  18436.5\n",
      "              VALUE    growth\n",
      "DATE                         \n",
      "2008-12-31  14549.9       NaN\n",
      "2009-12-31  14566.5  0.114090\n",
      "2010-12-31  15230.2  4.556345\n",
      "2011-12-31  15785.3  3.644732\n",
      "2012-12-31  16297.3  3.243524\n",
      "2013-12-31  16999.9  4.311144\n",
      "2014-12-31  17692.2  4.072377\n",
      "2015-12-31  18222.8  2.999062\n",
      "2016-12-31  18436.5  1.172707\n"
     ]
    }
   ],
   "source": [
    "# Computing percentage growth of GDP\n",
    "\n",
    "gdp_usa = pd.read_csv(data_folder + \"gdp_usa.csv\", index_col='DATE', parse_dates=True)\n",
    "gdp_china = pd.read_csv(data_folder + \"gdp_china.csv\", index_col='Year', parse_dates=True)\n",
    "\n",
    "#USA\n",
    "\n",
    "# Slice all the gdp data from 2008 onward: post2008\n",
    "post2008 = gdp_usa.loc['2008':]\n",
    "\n",
    "# Print the last 8 rows of post2008\n",
    "print(post2008.tail(8))\n",
    "\n",
    "# Resample post2008 by year, keeping last(): yearly\n",
    "yearly = post2008.resample('A').last()  \n",
    "\n",
    "# Print yearly\n",
    "print(yearly)\n",
    "\n",
    "# Compute percentage growth of yearly: yearly['growth']\n",
    "yearly['growth'] = yearly.pct_change() * 100\n",
    "\n",
    "# Print yearly again\n",
    "print(yearly)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercício 13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   Open        Close\n",
      "Date                                \n",
      "2015-01-02  2058.899902  2058.199951\n",
      "2015-01-05  2054.439941  2020.579956\n",
      "2015-01-06  2022.150024  2002.609985\n",
      "2015-01-07  2005.550049  2025.900024\n",
      "2015-01-08  2030.609985  2062.139893\n",
      "                   Open        Close\n",
      "Date                                \n",
      "2015-01-02  1340.364425  1339.908750\n",
      "2015-01-05  1348.616555  1326.389506\n",
      "2015-01-06  1332.515980  1319.639876\n",
      "2015-01-07  1330.562125  1344.063112\n",
      "2015-01-08  1343.268811  1364.126161\n"
     ]
    }
   ],
   "source": [
    "# Converting currency of stocks\n",
    "\n",
    "sp500 = pd.read_csv(data_folder + \"sp500.csv\", index_col='Date', parse_dates=True)\n",
    "exchange = pd.read_csv(data_folder + \"exchange.csv\", index_col='Date', parse_dates=True)\n",
    "\n",
    "# Subset 'Open' & 'Close' columns from sp500: dollars\n",
    "dollars = sp500[['Open', 'Close']]\n",
    "\n",
    "# Print the head of dollars\n",
    "print(dollars.head(5))\n",
    "\n",
    "# Convert dollars to pounds: pounds\n",
    "pounds = dollars.multiply(exchange['GBP/USD'], axis='rows')\n",
    "\n",
    "# Print the head of pounds\n",
    "print(pounds.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CHAPTER 2 - Concatenating data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercício 1 - Appending & concatenating Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Int64Index([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  0,  1,  2,  3,  4,  5,  6,  7,\n",
      "             8,  9, 10, 11, 12, 13, 14, 15, 16],\n",
      "           dtype='int64')\n",
      "3    NH\n",
      "3    MD\n",
      "dtype: object\n",
      "RangeIndex(start=0, stop=26, step=1)\n",
      "Int64Index([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  0,  1,  2,  3,  4,  5,  6,  7,\n",
      "             8,  9, 10, 11, 12, 13, 14, 15, 16],\n",
      "           dtype='int64')\n"
     ]
    }
   ],
   "source": [
    "#vídeo\n",
    "#Appending & concatenating Series\n",
    "\n",
    "# ● .append(): Series & DataFrame method\n",
    "#      s1.append(s2)   ----->   Stacks rows of s2 below s1\n",
    "\n",
    "# ● concat(): pandas module function\n",
    "#      pd.concat([s1, s2, s3])   ----->  Can stack row-wise and/or column-wise\n",
    "\n",
    "# concat() & .append()\n",
    "# ● Equivalence of concat() & .append():\n",
    "#    ● result1 = pd.concat([s1, s2, s3])\n",
    "#    ● result2 = s1.append(s2).append(s3)\n",
    "# ● result1 == result2 elementwise\n",
    "\n",
    "#EXEMPLO\n",
    "\n",
    "# Series of US states\n",
    "northeast = pd.Series(['CT', 'ME', 'MA', 'NH', 'RI', 'VT', 'NJ', 'NY', 'PA'])\n",
    "south = pd.Series(['DE', 'FL', 'GA', 'MD', 'NC', 'SC', 'VA', 'DC', 'WV', 'AL', 'KY', 'MS', 'TN', 'AR', 'LA', 'OK', 'TX'])\n",
    "midwest = pd.Series(['IL', 'IN', 'MN', 'MO', 'NE', 'ND', 'SD', 'IA', 'KS', 'MI', 'OH', 'WI'])\n",
    "west = pd.Series(['AZ', 'CO', 'ID', 'MT', 'NV', 'NM', 'UT', 'WY', 'AK', 'CA', 'HI', 'OR','WA'])\n",
    "\n",
    "# Using .append()\n",
    "east = northeast.append(south)\n",
    "east\n",
    "# The appended Index\n",
    "print(east.index)    # não 'continua' o index\n",
    "print(east.loc[3])   # <--- e por isso mostra o [3] de cada uma\n",
    "\n",
    "\n",
    "# Using .reset_index()\n",
    "new_east = northeast.append(south).reset_index(drop=True)   # já cria um index ordenado de 0 a 26\n",
    "print(new_east.index)\n",
    "\n",
    "# Using concat()\n",
    "east = pd.concat([northeast, south])       \n",
    "print(east.index)\n",
    "\n",
    "# Using ignore_index\n",
    "new_east = pd.concat([northeast, south], ignore_index=True)     # maneira de criar o index ordenado de 0 a 26 com o .concat()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercício 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Total\n",
      "NOC        \n",
      "USA  1052.0\n",
      "URS   584.0\n",
      "GBR   505.0\n",
      "FRA   475.0\n",
      "GER   454.0\n",
      "      Total\n",
      "NOC        \n",
      "USA  1195.0\n",
      "URS   627.0\n",
      "GBR   591.0\n",
      "FRA   461.0\n",
      "GER   350.0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Total</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NOC</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>USA</th>\n",
       "      <td>1052.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>USA</th>\n",
       "      <td>1195.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Total\n",
       "NOC        \n",
       "USA  1052.0\n",
       "USA  1195.0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Appending Series with nonunique Indices\n",
    "\n",
    "bronze5 = bronze[['NOC', 'Total']].head(5)\n",
    "bronze5.index = bronze5['NOC']\n",
    "del bronze5['NOC']\n",
    "print(bronze5)\n",
    "\n",
    "silver5 = silver[['NOC', 'Total']].head(5)\n",
    "silver5.index = silver5['NOC']\n",
    "del silver5['NOC']\n",
    "print(silver5)\n",
    "\n",
    "# If you were to run the command combined = bronze5.append(silver5), how many rows would combined have?\n",
    "\n",
    "combined = bronze5.append(silver5)  # 10\n",
    "\n",
    "# And how many rows would combined.loc['United States'] return? \n",
    "\n",
    "combined.loc['USA']   # 2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercício 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date\n",
      "2015-01-27 07:11:55    18\n",
      "2015-02-02 08:33:01     3\n",
      "2015-02-02 20:54:49     9\n",
      "Name: Units, dtype: int64\n",
      "Date\n",
      "2015-02-26 08:57:45     4\n",
      "2015-02-26 08:58:51     1\n",
      "2015-03-06 10:11:45    17\n",
      "2015-03-06 02:03:56    17\n",
      "Name: Units, dtype: int64\n",
      "\n",
      "642\n"
     ]
    }
   ],
   "source": [
    "# Appending pandas Series\n",
    "\n",
    "jan = pd.read_csv(data_folder + \"sales-jan-2015.csv\", index_col='Date', parse_dates=True)\n",
    "feb = pd.read_csv(data_folder + \"sales-feb-2015.csv\", index_col='Date', parse_dates=True)\n",
    "mar = pd.read_csv(data_folder + \"sales-mar-2015.csv\", index_col='Date', parse_dates=True)\n",
    "\n",
    "# Extract the 'Units' column from jan: jan_units\n",
    "jan_units = jan['Units']\n",
    "\n",
    "# Extract the 'Units' column from feb: feb_units\n",
    "feb_units = feb['Units']\n",
    "\n",
    "# Extract the 'Units' column from mar: mar_units\n",
    "mar_units = mar['Units']\n",
    "\n",
    "# Append feb_units and then mar_units to jan_units: quarter1\n",
    "quarter1 = jan_units.append(feb_units).append(mar_units)              # fazer o chaining\n",
    "\n",
    "# Print the first slice from quarter1\n",
    "print(quarter1.loc['jan 27, 2015':'feb 2, 2015'])\n",
    "\n",
    "# Print the second slice from quarter1\n",
    "print(quarter1.loc['feb 26, 2015':'mar 7, 2015'])\n",
    "\n",
    "# Compute & print total sales in quarter1\n",
    "print(\"\")\n",
    "print(quarter1.sum())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercício 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date\n",
      "2015-01-27 07:11:55    18\n",
      "2015-02-02 08:33:01     3\n",
      "2015-02-02 20:54:49     9\n",
      "Name: Units, dtype: int64\n",
      "Date\n",
      "2015-02-26 08:57:45     4\n",
      "2015-02-26 08:58:51     1\n",
      "2015-03-06 10:11:45    17\n",
      "2015-03-06 02:03:56    17\n",
      "Name: Units, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Concatenating pandas Series along row axis    ------->  achieve the same result by concatenating Series instead.\n",
    "\n",
    "# Initialize empty list: units\n",
    "units = []\n",
    "\n",
    "# Build the list of Series\n",
    "for month in [jan, feb, mar]:\n",
    "    units.append(month['Units'])\n",
    "\n",
    "# Concatenate the list: quarter1\n",
    "quarter1 = pd.concat(units, axis='rows')\n",
    "\n",
    "# Print slices from quarter1\n",
    "print(quarter1.loc['jan 27, 2015':'feb 2, 2015'])\n",
    "print(quarter1.loc['feb 26, 2015':'mar 7, 2015'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercício 5 - Appending & concatenating DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't find program: 'false'\n"
     ]
    }
   ],
   "source": [
    "%%script false\n",
    "#vídeo\n",
    "#Appending & concatenating DataFrames\n",
    "\n",
    "pd.concat([population, unemployment], axis=0)  #'rows'  ---> é o default\n",
    "pd.concat([population, unemployment], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercício 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19455, 4)\n",
      "(1935, 4)\n",
      "(21390, 4)\n",
      "         name gender  count  year\n",
      "1283   Morgan      M     23  1881\n",
      "2096   Morgan      F   1769  1981\n",
      "14390  Morgan      M    766  1981\n"
     ]
    }
   ],
   "source": [
    "# Appending DataFrames with ignore_index\n",
    "\n",
    "# MODIFIQUEI: pus títulos para as colunas\n",
    "names_1881 = pd.read_csv(data_folder + \"names1881.csv\", names=['name', 'gender', 'count'])\n",
    "names_1981 = pd.read_csv(data_folder + \"names1981.csv\", names=['name', 'gender', 'count'])\n",
    "\n",
    "# Add 'year' column to names_1881 and names_1981\n",
    "names_1881['year'] = 1881\n",
    "names_1981['year'] = 1981\n",
    "\n",
    "# Append names_1981 after names_1881 with ignore_index=True: combined_names\n",
    "combined_names = names_1881.append(names_1981, ignore_index=True)\n",
    "\n",
    "# Print shapes of names_1981, names_1881, and combined_names\n",
    "print(names_1981.shape)\n",
    "print(names_1881.shape)\n",
    "print(combined_names.shape)\n",
    "\n",
    "# Print all rows that contain the name 'Morgan'\n",
    "print(combined_names.loc[combined_names['name'] == 'Morgan'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercício 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't find program: 'false'\n"
     ]
    }
   ],
   "source": [
    "%%script false\n",
    "# Concatenating pandas DataFrames along column axis\n",
    "\n",
    "# Concatenate weather_max and weather_mean horizontally: weather\n",
    "weather = pd.concat([weather_max, weather_mean], axis='columns')\n",
    "\n",
    "# Print weather\n",
    "# print(weather)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercício 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                bronze  silver    gold\n",
      "France           475.0   461.0     NaN\n",
      "Germany          454.0     NaN   407.0\n",
      "Italy              NaN   394.0   460.0\n",
      "Soviet Union     584.0   627.0   838.0\n",
      "United Kingdom   505.0   591.0   498.0\n",
      "United States   1052.0  1195.0  2088.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Utilizador\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:27: FutureWarning: Sorting because non-concatenation axis is not aligned. A future version\n",
      "of pandas will change to not sort by default.\n",
      "\n",
      "To accept the future behavior, pass 'sort=False'.\n",
      "\n",
      "To retain the current behavior and silence the warning, pass 'sort=True'.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Reading multiple files to build a DataFrame                                     <-------------------  IMP.\n",
    "\n",
    "bronze_top5 = pd.read_csv(data_folder + \"bronze_top5.csv\")\n",
    "silver_top5 = pd.read_csv(data_folder + \"silver_top5.csv\")\n",
    "gold_top5 = pd.read_csv(data_folder + \"gold_top5.csv\")\n",
    "################\n",
    "\n",
    "medals = []\n",
    "medal_types = ['bronze', 'silver', 'gold']\n",
    "\n",
    "\n",
    "for medal in medal_types:\n",
    "\n",
    "    # Create the file name: file_name\n",
    "    file_name = data_folder + \"%s_top5.csv\" % medal\n",
    "    \n",
    "    # Create list of column names: columns\n",
    "    columns = ['Country', medal]\n",
    "    \n",
    "    # Read file_name into a DataFrame: df\n",
    "    medal_df = pd.read_csv(file_name, header=0, index_col='Country', names=columns)\n",
    "\n",
    "    # Append medal_df to medals\n",
    "    medals.append(medal_df)\n",
    "\n",
    "# Concatenate medals horizontally: medals\n",
    "medals = pd.concat(medals, axis='columns')\n",
    "\n",
    "# Print medals\n",
    "print(medals)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora exemplificando usando os ficheiros maiores:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                Bronze  Silver    Gold\n",
      "Country                               \n",
      "United States   1052.0  1195.0  2088.0\n",
      "Soviet Union     584.0   627.0   838.0\n",
      "United Kingdom   505.0   591.0   498.0\n",
      "France           475.0   461.0   378.0\n",
      "Germany          454.0   350.0   407.0\n"
     ]
    }
   ],
   "source": [
    "medals = []\n",
    "medal_types = ['Bronze', 'Silver', 'Gold']\n",
    "\n",
    "for medal in medal_types:\n",
    "\n",
    "    # Create the file name: file_name\n",
    "    file_name = data_folder + \"%s.csv\" % medal\n",
    "    \n",
    "    # Create list of column names: columns\n",
    "    columns = ['NOC', 'Country', medal]\n",
    "    \n",
    "    # Read file_name into a DataFrame: df\n",
    "    medal_df = pd.read_csv(file_name, header=0, index_col='Country', names=columns)\n",
    "\n",
    "    # Append medal_df to medals\n",
    "    medals.append(medal_df)\n",
    "\n",
    "# Concatenate medals horizontally: medals\n",
    "medals = pd.concat(medals, axis='columns')\n",
    "\n",
    "del medals['NOC']\n",
    "# Print medals\n",
    "print(medals.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercício 9 - Concatenation, keys, & MultiIndexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't find program: 'false'\n"
     ]
    }
   ],
   "source": [
    "%%script false\n",
    "#vídeo\n",
    "#Concatenation, keys, & MultiIndexes           \n",
    "\n",
    "# COMMON COLUMNS AND ROWS\n",
    "\n",
    "rain2013 = pd.read_csv('q1_rainfall_2013.csv', index_col='Month', parse_dates=True)   # file1\n",
    "rain2014 = pd.read_csv('q1_rainfall_2014.csv', index_col='Month', parse_dates=True)   #file2\n",
    "\n",
    "pd.concat([rain2013, rain2014], axis=0)\n",
    "\n",
    "rain1314 = pd.concat([rain2013, rain2014], keys=[2013, 2014], axis=0)           # Using multi-index on rows\n",
    "\n",
    "rain1314.loc[2014]      # Accessing a multi-index\n",
    "\n",
    "\n",
    "rain1314 = pd.concat([rain2013, rain2014], axis='columns')     # Concatenating columns  - como aqui as colunas têm o mesmo nome:\n",
    "\n",
    "rain1314 = pd.concat([rain2013, rain2014], keys=[2013, 2014], axis='columns')    # Using a multi-index on columns\n",
    "\n",
    "rain1314[2013]\n",
    "\n",
    "rain_dict = {2013: rain2013, 2014: rain2014}              \n",
    "rain1314 = pd.concat(rain_dict, axis='columns')             # pd.concat() with dict\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercício 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        Total\n",
      "       Country               \n",
      "bronze United States   1052.0\n",
      "       Soviet Union     584.0\n",
      "       United Kingdom   505.0\n",
      "       France           475.0\n",
      "       Germany          454.0\n",
      "silver United States   1195.0\n",
      "       Soviet Union     627.0\n",
      "       United Kingdom   591.0\n",
      "       France           461.0\n",
      "       Italy            394.0\n",
      "gold   United States   2088.0\n",
      "       Soviet Union     838.0\n",
      "       United Kingdom   498.0\n",
      "       Italy            460.0\n",
      "       Germany          407.0\n"
     ]
    }
   ],
   "source": [
    "# Concatenating vertically to get MultiIndexed rows\n",
    "\n",
    "medals = []\n",
    "medal_types = ['bronze', 'silver', 'gold']\n",
    "\n",
    "for medal in medal_types:\n",
    "\n",
    "    file_name = data_folder + \"%s_top5.csv\" % medal\n",
    "    \n",
    "    # Read file_name into a DataFrame: medal_df\n",
    "    medal_df = pd.read_csv(file_name, index_col='Country')\n",
    "    \n",
    "    # Append medal_df to medals\n",
    "    medals.append(medal_df)\n",
    "    \n",
    "# Concatenate medals (rows by default): medals\n",
    "medals = pd.concat(medals, keys=['bronze', 'silver', 'gold'])\n",
    "\n",
    "# Print medals in entirety\n",
    "print(medals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercício 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total    454.0\n",
      "Name: (bronze, Germany), dtype: float64\n",
      "                 Total\n",
      "Country               \n",
      "France           461.0\n",
      "Italy            394.0\n",
      "Soviet Union     627.0\n",
      "United Kingdom   591.0\n",
      "United States   1195.0\n",
      "                       Total\n",
      "       Country              \n",
      "bronze United Kingdom  505.0\n",
      "gold   United Kingdom  498.0\n",
      "silver United Kingdom  591.0\n"
     ]
    }
   ],
   "source": [
    "# Slicing MultiIndexed DataFrames\n",
    "\n",
    "# Your task is to sort the DataFrame and to use the pd.IndexSlice to extract specific slices.  #NÃO ESQUECER, pd.IndexSlice\n",
    "\n",
    "\n",
    "# Sort the entries of medals: medals_sorted\n",
    "medals_sorted = medals.sort_index(level=0)\n",
    "\n",
    "# Print the number of Bronze medals won by Germany\n",
    "print(medals_sorted.loc[('bronze','Germany')])\n",
    "\n",
    "# Print data about silver medals\n",
    "print(medals_sorted.loc['silver'])\n",
    "\n",
    "# Create alias for pd.IndexSlice: idx\n",
    "idx = pd.IndexSlice    # A slicer pd.IndexSlice is required when slicing on the inner level of a MultiIndex. Don't forget, inner\n",
    "\n",
    "# Print all the data on medals won by the United Kingdom\n",
    "print(medals_sorted.loc[idx[:, 'United Kingdom'], :])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercício 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 20 entries, 2015-02-02 08:33:01 to 2015-02-26 08:58:51\n",
      "Data columns (total 9 columns):\n",
      "(Hardware, Company)    5 non-null object\n",
      "(Hardware, Product)    5 non-null object\n",
      "(Hardware, Units)      5 non-null float64\n",
      "(Software, Company)    9 non-null object\n",
      "(Software, Product)    9 non-null object\n",
      "(Software, Units)      9 non-null float64\n",
      "(Service, Company)     6 non-null object\n",
      "(Service, Product)     6 non-null object\n",
      "(Service, Units)       6 non-null float64\n",
      "dtypes: float64(3), object(6)\n",
      "memory usage: 1.6+ KB\n",
      "None\n",
      "==============================================\n",
      "                            Hardware         Software Service\n",
      "                             Company          Company Company\n",
      "Date                                                         \n",
      "2015-02-02 08:33:01              NaN            Hooli     NaN\n",
      "2015-02-02 20:54:49        Mediacore              NaN     NaN\n",
      "2015-02-03 14:14:18              NaN          Initech     NaN\n",
      "2015-02-04 15:36:29              NaN        Streeplex     NaN\n",
      "2015-02-04 21:52:45  Acme Coporation              NaN     NaN\n",
      "2015-02-05 01:53:06              NaN  Acme Coporation     NaN\n",
      "2015-02-05 22:05:03              NaN              NaN   Hooli\n",
      "2015-02-07 22:58:10  Acme Coporation              NaN     NaN\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"3\" halign=\"left\">Hardware</th>\n",
       "      <th colspan=\"3\" halign=\"left\">Software</th>\n",
       "      <th colspan=\"3\" halign=\"left\">Service</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>Company</th>\n",
       "      <th>Product</th>\n",
       "      <th>Units</th>\n",
       "      <th>Company</th>\n",
       "      <th>Product</th>\n",
       "      <th>Units</th>\n",
       "      <th>Company</th>\n",
       "      <th>Product</th>\n",
       "      <th>Units</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2015-02-02 08:33:01</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Hooli</td>\n",
       "      <td>Software</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-02-02 20:54:49</th>\n",
       "      <td>Mediacore</td>\n",
       "      <td>Hardware</td>\n",
       "      <td>9.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-02-03 14:14:18</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Initech</td>\n",
       "      <td>Software</td>\n",
       "      <td>13.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2015-02-04 15:36:29</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Streeplex</td>\n",
       "      <td>Software</td>\n",
       "      <td>13.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      Hardware                   Software                  \\\n",
       "                       Company   Product Units    Company   Product Units   \n",
       "Date                                                                        \n",
       "2015-02-02 08:33:01        NaN       NaN   NaN      Hooli  Software   3.0   \n",
       "2015-02-02 20:54:49  Mediacore  Hardware   9.0        NaN       NaN   NaN   \n",
       "2015-02-03 14:14:18        NaN       NaN   NaN    Initech  Software  13.0   \n",
       "2015-02-04 15:36:29        NaN       NaN   NaN  Streeplex  Software  13.0   \n",
       "\n",
       "                    Service                \n",
       "                    Company Product Units  \n",
       "Date                                       \n",
       "2015-02-02 08:33:01     NaN     NaN   NaN  \n",
       "2015-02-02 20:54:49     NaN     NaN   NaN  \n",
       "2015-02-03 14:14:18     NaN     NaN   NaN  \n",
       "2015-02-04 15:36:29     NaN     NaN   NaN  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Concatenating horizontally to get MultiIndexed columns\n",
    "\n",
    "# Your task is to concatenate the DataFrames horizontally and to create a MultiIndex on the columns. \n",
    "# From there, you can summarize the resulting DataFrame and slice some information from it.\n",
    "\n",
    "hardware = pd.read_csv(data_folder + \"feb-sales-Hardware.csv\", index_col='Date', parse_dates=True)\n",
    "service = pd.read_csv(data_folder + \"feb-sales-Service.csv\", index_col='Date', parse_dates=True)\n",
    "software = pd.read_csv(data_folder + \"feb-sales-Software.csv\", index_col='Date', parse_dates=True)\n",
    "\n",
    "################\n",
    "\n",
    "# Concatenate the 3 dataframes: february\n",
    "february = pd.concat([hardware, software, service], axis='columns', keys=['Hardware', 'Software', 'Service'])\n",
    "\n",
    "# Print february.info()\n",
    "print(february.info())\n",
    "print(\"==============================================\")\n",
    "\n",
    "# Assign pd.IndexSlice: idx\n",
    "idx = pd.IndexSlice\n",
    "\n",
    "# Create the slice: slice_2_8\n",
    "slice_2_8 = february.loc['2015-02-02':'2015-02-08', idx[:, 'Company']]\n",
    "\n",
    "# Print slice_2_8\n",
    "print(slice_2_8)\n",
    "\n",
    "february.head(4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercício 13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          Units\n",
      "         Company               \n",
      "february Acme Coporation     34\n",
      "         Hooli               30\n",
      "         Initech             30\n",
      "         Mediacore           45\n",
      "         Streeplex           37\n",
      "january  Acme Coporation     76\n",
      "         Hooli               70\n",
      "         Initech             37\n",
      "         Mediacore           15\n",
      "         Streeplex           50\n",
      "march    Acme Coporation      5\n",
      "         Hooli               37\n",
      "         Initech             68\n",
      "         Mediacore           68\n",
      "         Streeplex           40\n",
      "=======================================================\n",
      "                    Units\n",
      "         Company         \n",
      "february Mediacore     45\n",
      "january  Mediacore     15\n",
      "march    Mediacore     68\n"
     ]
    }
   ],
   "source": [
    "# Concatenating DataFrames from a dict\n",
    "\n",
    "jan = pd.read_csv(data_folder + \"sales-jan-2015.csv\", index_col='Date', parse_dates=True)\n",
    "feb = pd.read_csv(data_folder + \"sales-feb-2015.csv\", index_col='Date', parse_dates=True)\n",
    "mar = pd.read_csv(data_folder + \"sales-mar-2015.csv\", index_col='Date', parse_dates=True)\n",
    "#######################\n",
    "\n",
    "# Make the list of tuples: month_list\n",
    "month_list = [('january', jan), ('february', feb), ('march', mar)]\n",
    "\n",
    "# Create an empty dictionary: month_dict\n",
    "month_dict = {}\n",
    "\n",
    "for month_name, month_data in month_list:\n",
    "\n",
    "    # Group month_data: month_dict[month_name]\n",
    "    month_dict[month_name] = month_data.groupby('Company').sum()\n",
    "\n",
    "# Concatenate data in month_dict: sales\n",
    "sales = pd.concat(month_dict)\n",
    "\n",
    "# Print sales\n",
    "print(sales)\n",
    "print(\"=======================================================\")\n",
    "\n",
    "# Print all sales by Mediacore\n",
    "idx = pd.IndexSlice\n",
    "print(sales.loc[idx[:, 'Mediacore'], :])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercício 14 - Outer & inner joins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't find program: 'false'\n"
     ]
    }
   ],
   "source": [
    "%%script false\n",
    "#vídeo\n",
    "#Outer & inner joins\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "A = np.arange(8).reshape(2,4) + 0.1\n",
    "B = np.arange(6).reshape(2,3) + 0.2\n",
    "C = np.arange(12).reshape(3,4) + 0.3\n",
    "\n",
    "np.hstack([B, A])                    # Stacking arrays horizontally\n",
    "np.concatenate([B, A], axis=1)       # Stacking arrays horizontally\n",
    "\n",
    "np.vstack([A, C])                 # Stacking arrays vertically\n",
    "np.concatenate([A, C], axis=0)    # Stacking arrays vertically\n",
    "\n",
    "# Incompatible array dimensions\n",
    "np.concatenate([A, B], axis=0) # incompatible columns\n",
    "np.concatenate([A, C], axis=1) # incompatible rows\n",
    "\n",
    "\n",
    "# EXEMPLO\n",
    "# Population & unemployment data\n",
    "population = pd.read_csv('population_00.csv', index_col=0)\n",
    "unemployment = pd.read_csv('unemployment_00.csv', index_col=0)\n",
    "\n",
    "population_array = np.array(population)    # Converting to arrays\n",
    "population_array    #print() ---shape: (4, 1)   # Index info is lost\n",
    "\n",
    "unemployment_array = np.array(unemployment)\n",
    "population_array    #print() ---shape: (4, 2)   # Index info is lost\n",
    "\n",
    "\n",
    "# Manipulating data as arrays\n",
    "np.concatenate([population_array, unemployment_array], axis='columns'))         # shape (4, 3)\n",
    "\n",
    "# Joins\n",
    "\n",
    "# ● Joining tables: Combining rows of multiple tables\n",
    "#    ● Outer join\n",
    "#        ● Union of index sets (all labels, no repetition)\n",
    "#        ● Missing fields filled with NaN\n",
    "#    ● Inner join\n",
    "#        ● Intersection of index sets (only common labels)\n",
    "\n",
    "pd.concat([population, unemployment], axis=1, join='inner')    # Concatenation & inner join\n",
    "\n",
    "pd.concat([population, unemployment], axis=1, join='outer')    # Concatenation & outer join\n",
    "\n",
    "\n",
    "pd.concat([population, unemployment], join='inner', axis=0)  # Inner join on other axis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercício 15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                bronze  silver    gold\n",
      "                 Total   Total   Total\n",
      "Country                               \n",
      "United States   1052.0  1195.0  2088.0\n",
      "Soviet Union     584.0   627.0   838.0\n",
      "United Kingdom   505.0   591.0   498.0\n"
     ]
    }
   ],
   "source": [
    "# Concatenating DataFrames with inner join\n",
    "\n",
    "bronze_top5 = pd.read_csv(data_folder + \"bronze_top5.csv\", index_col='Country')\n",
    "silver_top5 = pd.read_csv(data_folder + \"silver_top5.csv\", index_col='Country')\n",
    "gold_top5 = pd.read_csv(data_folder + \"gold_top5.csv\", index_col='Country')\n",
    "#####################################\n",
    "\n",
    "# Create the list of DataFrames: medal_list\n",
    "medal_list = [bronze_top5, silver_top5, gold_top5]\n",
    "\n",
    "# Concatenate medal_list horizontally using an inner join: medals\n",
    "medals = pd.concat(medal_list, axis='columns', keys=['bronze', 'silver', 'gold'], join='inner')\n",
    "\n",
    "# Print medals\n",
    "print(medals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercício 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't find program: 'false'\n"
     ]
    }
   ],
   "source": [
    "%%script false\n",
    "# Resampling & concatenating DataFrames with inner join                                                  ###????\n",
    " \n",
    "us = pd.read_csv(data_folder + \"gdp_usa2.csv\", index_col='Year', parse_dates=True)\n",
    "china = pd.read_csv(data_folder + \"gdp_china.csv\", index_col='Year', parse_dates=True)\n",
    "######################\n",
    "\n",
    "# os dados dos USA são quatrimestrais, os da China anuais, por isso temos que fazer um resample e depois o inner join\n",
    "\n",
    "\n",
    "# Resample and tidy china: china_annual\n",
    "\n",
    "# Make a new DataFrame china_annual by resampling the DataFrame china with .resample('A') (i.e., with annual frequency) and chaining two method calls:\n",
    "#    Chain .pct_change(10) as an aggregation method to compute the percentage change with an offset of ten years.\n",
    "#    Chain .dropna() to eliminate rows containing null values.\n",
    "china_annual = china.resample('A').pct_change(10).dropna()\n",
    "\n",
    "\n",
    "# Resample and tidy us: us_annual\n",
    "us_annual = us.resample('A').pct_change(10).dropna()\n",
    "\n",
    "# Concatenate china_annual and us_annual: gdp\n",
    "gdp = pd.concat([china_annual, us_annual], axis='columns', join='inner')\n",
    "\n",
    "# Print the result of resampling gdp every decade (i.e., using .resample('10A')) and aggregating with the method .last()\n",
    "print(gdp.resample('10A').last())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 3 - Merging data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercício 1 - Merging DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't find program: 'false'\n"
     ]
    }
   ],
   "source": [
    "%%script false\n",
    "#vídeo\n",
    "#Merging DataFrames\n",
    "\n",
    "# Medal DataFrames \n",
    "pd.merge(bronze, gold)   # Empty dataframe because the columns have the exact same name\n",
    "\n",
    "pd.merge(bronze, gold, on='Country')   # Merging on\n",
    "\n",
    "pd.merge(bronze, gold, on=['NOC', 'Country'])  # Merging on  multiple columns\n",
    "\n",
    "pd.merge(bronze, gold, on=['NOC', 'Country'], suffixes=['_bronze', '_gold']).head(4)  # Using suffixes\n",
    "\n",
    "# Specifying columns to merge\n",
    "\n",
    "pd.merge(counties, cities, left_on='CITY NAME', right_on='City')     \n",
    "\n",
    "# > Têm linhas iguais(nomes de cidades) mas nomes de colunas diferentes, por isso temos que especificar:\n",
    "#      a 'CITY NAME' de counties e 'City' de cities\n",
    "\n",
    "# pd.merge(cities, counties, left_on='City', right_on='CITY NAME')   # Switching left/right DataFrames\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercício 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          city  revenue       city   manager\n",
      "0       Austin      100     Austin  Charlers\n",
      "1       Denver       83     Denver      Joel\n",
      "2  Springfield        4  Mendocino     Brett\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city</th>\n",
       "      <th>revenue</th>\n",
       "      <th>manager</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Austin</td>\n",
       "      <td>100</td>\n",
       "      <td>Charlers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Denver</td>\n",
       "      <td>83</td>\n",
       "      <td>Joel</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     city  revenue   manager\n",
       "0  Austin      100  Charlers\n",
       "1  Denver       83      Joel"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merging company DataFrames\n",
    "\n",
    "revenue = pd.DataFrame({'city':['Austin', 'Denver', 'Springfield'], 'revenue':[100, 83, 4]})\n",
    "managers = pd.DataFrame({'city':['Austin', 'Denver', 'Mendocino'], 'manager':['Charlers', 'Joel', 'Brett']})\n",
    "\n",
    "print(pd.concat([revenue, managers], axis=1)) #só para ver\n",
    "\n",
    "combined = pd.merge(revenue, managers, on='city')\n",
    "\n",
    "# How many rows would combined have?\n",
    "combined\n",
    "# Resposta: 2  # the default strategy for pd.merge() is an inner join --> combined will have 2 rows."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercício 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   branch_id_x         city  revenue  branch_id_y   manager\n",
      "0           10       Austin      100           10  Charlers\n",
      "1           20       Denver       83           20      Joel\n",
      "2           30  Springfield        4           31     Sally\n",
      "3           47    Mendocino      200           47     Brett\n",
      "==============================================================\n",
      "   branch_id     city_x  revenue     city_y   manager\n",
      "0         10     Austin      100     Austin  Charlers\n",
      "1         20     Denver       83     Denver      Joel\n",
      "2         47  Mendocino      200  Mendocino     Brett\n"
     ]
    }
   ],
   "source": [
    "# Merging on a specific column\n",
    "\n",
    "#primeiro vou adicionar branch_id a cada df porque queriam fazer isso, assim como as outras alterações/adições:\n",
    "revenue = pd.DataFrame({'branch_id':[10, 20, 30, 47], 'city':['Austin', 'Denver', 'Springfield', 'Mendocino'], 'revenue':[100, 83, 4, 200]})\n",
    "managers = pd.DataFrame({'branch_id':[10, 20, 47, 31], 'city':['Austin', 'Denver', 'Mendocino', 'Springfield'], 'manager':['Charlers', 'Joel', 'Brett', 'Sally']})\n",
    "##########################\n",
    "\n",
    "# Merge revenue with managers on 'city': merge_by_city\n",
    "merge_by_city = pd.merge(revenue, managers, on='city')\n",
    "\n",
    "# Print merge_by_city\n",
    "print(merge_by_city)\n",
    "print(\"==============================================================\")\n",
    "\n",
    "# Merge revenue with managers on 'branch_id': merge_by_id\n",
    "merge_by_id = pd.merge(revenue, managers, on='branch_id')\n",
    "\n",
    "# Print merge_by_id\n",
    "print(merge_by_id)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercício 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>branch_id_x</th>\n",
       "      <th>city</th>\n",
       "      <th>revenue</th>\n",
       "      <th>state_x</th>\n",
       "      <th>branch</th>\n",
       "      <th>branch_id_y</th>\n",
       "      <th>manager</th>\n",
       "      <th>state_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>Austin</td>\n",
       "      <td>100</td>\n",
       "      <td>TX</td>\n",
       "      <td>Austin</td>\n",
       "      <td>10</td>\n",
       "      <td>Charlers</td>\n",
       "      <td>TX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20</td>\n",
       "      <td>Denver</td>\n",
       "      <td>83</td>\n",
       "      <td>CO</td>\n",
       "      <td>Denver</td>\n",
       "      <td>20</td>\n",
       "      <td>Joel</td>\n",
       "      <td>CO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30</td>\n",
       "      <td>Springfield</td>\n",
       "      <td>4</td>\n",
       "      <td>IL</td>\n",
       "      <td>Springfield</td>\n",
       "      <td>31</td>\n",
       "      <td>Sally</td>\n",
       "      <td>CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>47</td>\n",
       "      <td>Mendocino</td>\n",
       "      <td>200</td>\n",
       "      <td>CA</td>\n",
       "      <td>Mendocino</td>\n",
       "      <td>47</td>\n",
       "      <td>Brett</td>\n",
       "      <td>IL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   branch_id_x         city  revenue state_x       branch  branch_id_y  \\\n",
       "0           10       Austin      100      TX       Austin           10   \n",
       "1           20       Denver       83      CO       Denver           20   \n",
       "2           30  Springfield        4      IL  Springfield           31   \n",
       "3           47    Mendocino      200      CA    Mendocino           47   \n",
       "\n",
       "    manager state_y  \n",
       "0  Charlers      TX  \n",
       "1      Joel      CO  \n",
       "2     Sally      CA  \n",
       "3     Brett      IL  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merging on columns with non-matching labels\n",
    "\n",
    "revenue = pd.DataFrame({'branch_id':[10, 20, 30, 47], 'city':['Austin', 'Denver', 'Springfield', 'Mendocino'], 'revenue':[100, 83, 4, 200], 'state':['TX', 'CO', 'IL', 'CA']})\n",
    "managers = pd.DataFrame({'branch':['Austin', 'Denver', 'Mendocino', 'Springfield'], 'branch_id':[10, 20, 47, 31], 'manager':['Charlers', 'Joel', 'Brett', 'Sally'], 'state':['TX', 'CO', 'IL', 'CA']})\n",
    "##########################\n",
    "\n",
    "# Merge revenue & managers on 'city' & 'branch': combined\n",
    "combined = pd.merge(revenue, managers, left_on='city', right_on='branch')\n",
    "\n",
    "# Print combined\n",
    "combined\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercício 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   branch_id       city  revenue state   manager\n",
      "0         10     Austin      100    TX  Charlers\n",
      "1         20     Denver       83    CO      Joel\n",
      "2         47  Mendocino      200    CA     Brett\n"
     ]
    }
   ],
   "source": [
    "# Merging on multiple columns\n",
    "\n",
    "revenue = pd.DataFrame({'branch_id':[10, 20, 30, 47], 'city':['Austin', 'Denver', 'Springfield', 'Mendocino'], 'revenue':[100, 83, 4, 200]})\n",
    "managers = pd.DataFrame({'branch_id':[10, 20, 47, 31], 'city':['Austin', 'Denver', 'Mendocino', 'Springfield'], 'manager':['Charlers', 'Joel', 'Brett', 'Sally']})\n",
    "\n",
    "# Add 'state' column to revenue: revenue['state']\n",
    "revenue['state'] = ['TX','CO','IL','CA']\n",
    "\n",
    "# Add 'state' column to managers: managers['state']\n",
    "managers['state'] = ['TX','CO','CA','MO']\n",
    "\n",
    "# Merge revenue & managers on 'branch_id', 'city', & 'state': combined\n",
    "combined = pd.merge(revenue, managers, on=['branch_id', 'city', 'state'])\n",
    "\n",
    "# Print combined\n",
    "print(combined)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercício 6 - Joining DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't find program: 'false'\n"
     ]
    }
   ],
   "source": [
    "%%script false\n",
    "#vídeo\n",
    "#Joining DataFrames\n",
    "\n",
    "pd.merge(bronze, gold, on=['NOC', 'Country'], suffixes=['/bronze', '/gold'], how='inner')  # inner é o default para merge\n",
    "\n",
    "pd.merge(bronze, gold, on=['NOC', 'Country'], suffixes=['/bronze', '/gold'], how='left')  # mantém all rows of the left df\n",
    "\n",
    "pd.merge(bronze, gold, on=['NOC', 'Country'], suffixes=['/bronze', '/gold'], how='right')  # mantém all rows of the right df\n",
    "\n",
    "pd.merge(bronze, gold, on=['NOC', 'Country'], suffixes=['/bronze', '/gold'], how='outer')  # vê pela esq e dir -> aparecem todos\n",
    "\n",
    "##\n",
    "\n",
    "population.join(unemployment)   # Using .join(how=‘left')  -----> usa left por default\n",
    "population.join(unemployment, how= 'right') \n",
    "population.join(unemployment, how='inner') #só aparece 1 linha (cód postal 2860)\n",
    "population.join(unemployment, how= 'outer')\n",
    "\n",
    "# Which should you use?  --------> usar o que for mais simples para o caso\n",
    "\n",
    "# ● df1.append(df2): simply stacking vertically \n",
    "\n",
    "# ● pd.concat([df1, df2]):\n",
    "#      ● stacking many horizontally or vertically\n",
    "#      ● simple inner/outer joins on Indexes\n",
    "\n",
    "# ● df1.join(df2): inner/outer/left/right joins on Indexes\n",
    "\n",
    "# ● pd.merge([df1, df2]): many joins on multiple columns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercício 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city_rev</th>\n",
       "      <th>revenue</th>\n",
       "      <th>state_rev</th>\n",
       "      <th>city_mng</th>\n",
       "      <th>manager</th>\n",
       "      <th>state_mng</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>branch_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Austin</td>\n",
       "      <td>100.0</td>\n",
       "      <td>TX</td>\n",
       "      <td>Austin</td>\n",
       "      <td>Charlers</td>\n",
       "      <td>TX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Denver</td>\n",
       "      <td>83.0</td>\n",
       "      <td>CO</td>\n",
       "      <td>Denver</td>\n",
       "      <td>Joel</td>\n",
       "      <td>CO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Springfield</td>\n",
       "      <td>4.0</td>\n",
       "      <td>IL</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Springfield</td>\n",
       "      <td>Sally</td>\n",
       "      <td>CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>Mendocino</td>\n",
       "      <td>200.0</td>\n",
       "      <td>CA</td>\n",
       "      <td>Mendocino</td>\n",
       "      <td>Brett</td>\n",
       "      <td>IL</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              city_rev  revenue state_rev     city_mng   manager state_mng\n",
       "branch_id                                                                 \n",
       "10              Austin    100.0        TX       Austin  Charlers        TX\n",
       "20              Denver     83.0        CO       Denver      Joel        CO\n",
       "30         Springfield      4.0        IL          NaN       NaN       NaN\n",
       "31                 NaN      NaN       NaN  Springfield     Sally        CA\n",
       "47           Mendocino    200.0        CA    Mendocino     Brett        IL"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Joining by Index\n",
    "\n",
    "revenue = pd.DataFrame({'branch_id':[10, 20, 30, 47], 'city':['Austin', 'Denver', 'Springfield', 'Mendocino'], 'revenue':[100, 83, 4, 200], 'state':['TX', 'CO', 'IL', 'CA']})\n",
    "managers = pd.DataFrame({'branch_id':[10, 20, 47, 31], 'city':['Austin', 'Denver', 'Mendocino', 'Springfield'], 'manager':['Charlers', 'Joel', 'Brett', 'Sally'], 'state':['TX', 'CO', 'IL', 'CA']})\n",
    "revenue.set_index('branch_id', inplace=True)\n",
    "managers.set_index('branch_id', inplace=True)\n",
    "\n",
    "# Choose the function call below that will join the DataFrames on their indexes and return 5 rows \n",
    "# with index labels [10, 20, 30, 31, 47]\n",
    "\n",
    "revenue.join(managers, lsuffix='_rev', rsuffix='_mng', how='outer')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercício 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Couldn't find program: 'false'\n"
     ]
    }
   ],
   "source": [
    "%%script false\n",
    "# Choosing a joining strategy\n",
    "\n",
    "# Suppose you have two DataFrames: students (with columns 'StudentID', 'LastName', 'FirstName', and 'Major') and \n",
    "# midterm_results (with columns 'StudentID', 'Q1', 'Q2', and 'Q3' for their scores on midterm questions).\n",
    "\n",
    "# You want to combine the DataFrames into a single DataFrame grades, and be able to easily spot which students wrote \n",
    "# the midterm and which didn't (their midterm question scores 'Q1', 'Q2', & 'Q3' should be filled with NaN values).\n",
    "\n",
    "# You also want to drop rows from midterm_results in which the StudentID is not found in students.\n",
    "\n",
    "# Which of the following strategies gives the desired result?\n",
    "\n",
    "grades = pd.merge(students, midterm_results, how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercício 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   branch_id         city  revenue state  units\n",
      "0       10.0       Austin    100.0    TX      2\n",
      "1       20.0       Denver     83.0    CO      4\n",
      "2       30.0  Springfield      4.0    IL      1\n",
      "3       47.0    Mendocino    200.0    CA      1\n",
      "4        NaN  Springfield      NaN    MO      5\n",
      "==================================================================\n",
      "          city state  units  branch  branch_id   manager\n",
      "0    Mendocino    CA      1     NaN        NaN       NaN\n",
      "1       Denver    CO      4  Denver       20.0      Joel\n",
      "2       Austin    TX      2  Austin       10.0  Charlers\n",
      "3  Springfield    MO      5     NaN        NaN       NaN\n",
      "4  Springfield    IL      1     NaN        NaN       NaN\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>branch</th>\n",
       "      <th>branch_id</th>\n",
       "      <th>manager</th>\n",
       "      <th>state</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>units</th>\n",
       "      <th>branch_id</th>\n",
       "      <th>city</th>\n",
       "      <th>revenue</th>\n",
       "      <th>state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Austin</td>\n",
       "      <td>10.0</td>\n",
       "      <td>Charlers</td>\n",
       "      <td>TX</td>\n",
       "      <td>Mendocino</td>\n",
       "      <td>CA</td>\n",
       "      <td>1</td>\n",
       "      <td>10.0</td>\n",
       "      <td>Austin</td>\n",
       "      <td>100.0</td>\n",
       "      <td>TX</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Denver</td>\n",
       "      <td>20.0</td>\n",
       "      <td>Joel</td>\n",
       "      <td>CO</td>\n",
       "      <td>Denver</td>\n",
       "      <td>CO</td>\n",
       "      <td>4</td>\n",
       "      <td>20.0</td>\n",
       "      <td>Denver</td>\n",
       "      <td>83.0</td>\n",
       "      <td>CO</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mendocino</td>\n",
       "      <td>47.0</td>\n",
       "      <td>Brett</td>\n",
       "      <td>IL</td>\n",
       "      <td>Austin</td>\n",
       "      <td>TX</td>\n",
       "      <td>2</td>\n",
       "      <td>30.0</td>\n",
       "      <td>Springfield</td>\n",
       "      <td>4.0</td>\n",
       "      <td>IL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Springfield</td>\n",
       "      <td>31.0</td>\n",
       "      <td>Sally</td>\n",
       "      <td>CA</td>\n",
       "      <td>Springfield</td>\n",
       "      <td>MO</td>\n",
       "      <td>5</td>\n",
       "      <td>47.0</td>\n",
       "      <td>Mendocino</td>\n",
       "      <td>200.0</td>\n",
       "      <td>CA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Springfield</td>\n",
       "      <td>IL</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        branch  branch_id   manager state         city state  units  \\\n",
       "0       Austin       10.0  Charlers    TX    Mendocino    CA      1   \n",
       "1       Denver       20.0      Joel    CO       Denver    CO      4   \n",
       "2    Mendocino       47.0     Brett    IL       Austin    TX      2   \n",
       "3  Springfield       31.0     Sally    CA  Springfield    MO      5   \n",
       "4          NaN        NaN       NaN   NaN  Springfield    IL      1   \n",
       "\n",
       "   branch_id         city  revenue state  \n",
       "0       10.0       Austin    100.0    TX  \n",
       "1       20.0       Denver     83.0    CO  \n",
       "2       30.0  Springfield      4.0    IL  \n",
       "3       47.0    Mendocino    200.0    CA  \n",
       "4        NaN          NaN      NaN   NaN  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Left & right merging on multiple columns\n",
    "\n",
    "sales2 = pd.DataFrame({'city':['Mendocino', 'Denver', 'Austin', 'Springfield', 'Springfield'], 'state':['CA', 'CO', 'TX', 'MO', 'IL'], 'units':[1, 4, 2, 5, 1]})\n",
    "managers2 = managers.copy()\n",
    "managers2 = managers2.reset_index()\n",
    "managers2 = managers2[['city', 'branch_id', 'manager', 'state']]\n",
    "managers2.columns = ['branch', 'branch_id', 'manager', 'state']\n",
    "revenue2 = revenue.copy()\n",
    "revenue2 = revenue2.reset_index()\n",
    "#####################################################################################\n",
    "\n",
    "# In both cases, you're looking to figure out how to connect the fields in rows containing Springfield.\n",
    "\n",
    "# By merging revenue and sales with a right merge, you can identify the missing revenue values. \n",
    "# Here, you don't need to specify left_on or right_on because the columns to merge on have matching labels.\n",
    "revenue2_and_sales2 = pd.merge(revenue2, sales2, how='right', on=['city', 'state'])\n",
    "\n",
    "print(revenue2_and_sales2)\n",
    "print(\"==================================================================\")\n",
    "\n",
    "# By merging sales and managers with a left merge, you can identify the missing manager. Here, the columns to merge on have\n",
    "# conflicting labels, so you must specify left_on and right_on. \n",
    "sales2_and_managers2 = pd.merge(sales2, managers2, how='left', left_on=['city', 'state'], right_on=['branch', 'state'])\n",
    "\n",
    "print(sales2_and_managers2)\n",
    "\n",
    "pd.concat([managers2, sales2, revenue2], axis='columns')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercício 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          city state  units  branch  branch_id   manager  revenue\n",
      "0       Denver    CO      4  Denver       20.0      Joel     83.0\n",
      "1       Austin    TX      2  Austin       10.0  Charlers    100.0\n",
      "2  Springfield    MO      5     NaN        NaN       NaN      NaN\n",
      "=============================================================\n",
      "          city state  units  branch  branch_id   manager  revenue\n",
      "0    Mendocino    CA      1     NaN        NaN       NaN      NaN\n",
      "1       Denver    CO      4  Denver       20.0      Joel     83.0\n",
      "2       Austin    TX      2  Austin       10.0  Charlers    100.0\n",
      "3  Springfield    MO      5     NaN        NaN       NaN      NaN\n",
      "4  Springfield    IL      1     NaN        NaN       NaN      NaN\n",
      "5  Springfield    IL      1     NaN       30.0       NaN      4.0\n",
      "6    Mendocino    CA      1     NaN       47.0       NaN    200.0\n",
      "=============================================================\n",
      "          city state  units_x  branch  branch_id_x   manager  branch_id_y  \\\n",
      "0    Mendocino    CA        1     NaN          NaN       NaN         47.0   \n",
      "1       Denver    CO        4  Denver         20.0      Joel         20.0   \n",
      "2       Austin    TX        2  Austin         10.0  Charlers         10.0   \n",
      "3  Springfield    MO        5     NaN          NaN       NaN          NaN   \n",
      "4  Springfield    IL        1     NaN          NaN       NaN         30.0   \n",
      "\n",
      "   revenue  units_y  \n",
      "0    200.0        1  \n",
      "1     83.0        4  \n",
      "2    100.0        2  \n",
      "3      NaN        5  \n",
      "4      4.0        1  \n"
     ]
    }
   ],
   "source": [
    "# Merging DataFrames with outer join\n",
    "\n",
    "# Perform the first merge: merge_default\n",
    "merge_default = pd.merge(sales2_and_managers2, revenue2_and_sales2)   #inner by default\n",
    "\n",
    "# Print merge_default\n",
    "print(merge_default)\n",
    "print(\"=============================================================\")\n",
    "\n",
    "# Perform the second merge: merge_outer\n",
    "merge_outer = pd.merge(sales2_and_managers2, revenue2_and_sales2, how='outer')        \n",
    "\n",
    "# Print merge_outer\n",
    "print(merge_outer)\n",
    "print(\"=============================================================\")\n",
    "\n",
    "# Perform the third merge: merge_outer_on\n",
    "merge_outer_on = pd.merge(sales2_and_managers2, revenue2_and_sales2, how='outer', on=['city', 'state'])  \n",
    "\n",
    "# Print merge_outer_on\n",
    "print(merge_outer_on)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercício 11 - Ordered merges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>VALUE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>243.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>246.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>250.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>260.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>266.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>272.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>279.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>280.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>275.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>271.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>273.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>271.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>281.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>290.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>308.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>320.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>336.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>344.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>351.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>356.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>360.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>361.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>368.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>381.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>388.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>392.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>391.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>386.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>385.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>386.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>2082.820068</td>\n",
       "      <td>2097.060059</td>\n",
       "      <td>2082.820068</td>\n",
       "      <td>2089.169922</td>\n",
       "      <td>3.929600e+09</td>\n",
       "      <td>2089.169922</td>\n",
       "      <td>18222.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>2089.409912</td>\n",
       "      <td>2095.610107</td>\n",
       "      <td>2081.389893</td>\n",
       "      <td>2086.590088</td>\n",
       "      <td>3.587980e+09</td>\n",
       "      <td>2086.590088</td>\n",
       "      <td>18222.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>2084.419922</td>\n",
       "      <td>2094.120117</td>\n",
       "      <td>2070.290039</td>\n",
       "      <td>2089.139893</td>\n",
       "      <td>3.884930e+09</td>\n",
       "      <td>2089.139893</td>\n",
       "      <td>18222.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500</th>\n",
       "      <td>2089.300049</td>\n",
       "      <td>2093.000000</td>\n",
       "      <td>2086.300049</td>\n",
       "      <td>2088.870117</td>\n",
       "      <td>2.852940e+09</td>\n",
       "      <td>2088.870117</td>\n",
       "      <td>18222.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>2088.820068</td>\n",
       "      <td>2093.290039</td>\n",
       "      <td>2084.129883</td>\n",
       "      <td>2090.110107</td>\n",
       "      <td>1.466840e+09</td>\n",
       "      <td>2090.110107</td>\n",
       "      <td>18222.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>2090.949951</td>\n",
       "      <td>2093.810059</td>\n",
       "      <td>2080.409912</td>\n",
       "      <td>2080.409912</td>\n",
       "      <td>4.245030e+09</td>\n",
       "      <td>2080.409912</td>\n",
       "      <td>18222.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>2082.929932</td>\n",
       "      <td>2103.370117</td>\n",
       "      <td>2082.929932</td>\n",
       "      <td>2102.629883</td>\n",
       "      <td>3.712120e+09</td>\n",
       "      <td>2102.629883</td>\n",
       "      <td>18222.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>2101.709961</td>\n",
       "      <td>2104.270020</td>\n",
       "      <td>2077.110107</td>\n",
       "      <td>2079.510010</td>\n",
       "      <td>3.950640e+09</td>\n",
       "      <td>2079.510010</td>\n",
       "      <td>18222.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>505</th>\n",
       "      <td>2080.709961</td>\n",
       "      <td>2085.000000</td>\n",
       "      <td>2042.349976</td>\n",
       "      <td>2049.620117</td>\n",
       "      <td>4.306490e+09</td>\n",
       "      <td>2049.620117</td>\n",
       "      <td>18222.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>506</th>\n",
       "      <td>2051.239990</td>\n",
       "      <td>2093.840088</td>\n",
       "      <td>2051.239990</td>\n",
       "      <td>2091.689941</td>\n",
       "      <td>4.214910e+09</td>\n",
       "      <td>2091.689941</td>\n",
       "      <td>18222.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>507</th>\n",
       "      <td>2090.419922</td>\n",
       "      <td>2090.419922</td>\n",
       "      <td>2066.780029</td>\n",
       "      <td>2077.070068</td>\n",
       "      <td>4.043820e+09</td>\n",
       "      <td>2077.070068</td>\n",
       "      <td>18222.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>508</th>\n",
       "      <td>2073.389893</td>\n",
       "      <td>2073.850098</td>\n",
       "      <td>2052.320068</td>\n",
       "      <td>2063.590088</td>\n",
       "      <td>4.173570e+09</td>\n",
       "      <td>2063.590088</td>\n",
       "      <td>18222.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>509</th>\n",
       "      <td>2061.169922</td>\n",
       "      <td>2080.330078</td>\n",
       "      <td>2036.530029</td>\n",
       "      <td>2047.619995</td>\n",
       "      <td>4.385250e+09</td>\n",
       "      <td>2047.619995</td>\n",
       "      <td>18222.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>510</th>\n",
       "      <td>2047.930054</td>\n",
       "      <td>2067.649902</td>\n",
       "      <td>2045.670044</td>\n",
       "      <td>2052.229980</td>\n",
       "      <td>3.715150e+09</td>\n",
       "      <td>2052.229980</td>\n",
       "      <td>18222.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>511</th>\n",
       "      <td>2047.270020</td>\n",
       "      <td>2047.270020</td>\n",
       "      <td>2008.800049</td>\n",
       "      <td>2012.369995</td>\n",
       "      <td>4.301060e+09</td>\n",
       "      <td>2012.369995</td>\n",
       "      <td>18222.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>512</th>\n",
       "      <td>2013.369995</td>\n",
       "      <td>2022.920044</td>\n",
       "      <td>1993.260010</td>\n",
       "      <td>2021.939941</td>\n",
       "      <td>4.612440e+09</td>\n",
       "      <td>2021.939941</td>\n",
       "      <td>18222.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>513</th>\n",
       "      <td>2025.550049</td>\n",
       "      <td>2053.870117</td>\n",
       "      <td>2025.550049</td>\n",
       "      <td>2043.410034</td>\n",
       "      <td>4.353540e+09</td>\n",
       "      <td>2043.410034</td>\n",
       "      <td>18222.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>514</th>\n",
       "      <td>2046.500000</td>\n",
       "      <td>2076.719971</td>\n",
       "      <td>2042.430054</td>\n",
       "      <td>2073.070068</td>\n",
       "      <td>4.635450e+09</td>\n",
       "      <td>2073.070068</td>\n",
       "      <td>18222.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515</th>\n",
       "      <td>2073.760010</td>\n",
       "      <td>2076.370117</td>\n",
       "      <td>2041.660034</td>\n",
       "      <td>2041.890015</td>\n",
       "      <td>4.327390e+09</td>\n",
       "      <td>2041.890015</td>\n",
       "      <td>18222.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>516</th>\n",
       "      <td>2040.810059</td>\n",
       "      <td>2040.810059</td>\n",
       "      <td>2005.329956</td>\n",
       "      <td>2005.550049</td>\n",
       "      <td>6.683070e+09</td>\n",
       "      <td>2005.550049</td>\n",
       "      <td>18222.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>517</th>\n",
       "      <td>2010.270020</td>\n",
       "      <td>2022.900024</td>\n",
       "      <td>2005.930054</td>\n",
       "      <td>2021.150024</td>\n",
       "      <td>3.760280e+09</td>\n",
       "      <td>2021.150024</td>\n",
       "      <td>18222.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>518</th>\n",
       "      <td>2023.150024</td>\n",
       "      <td>2042.739990</td>\n",
       "      <td>2020.489990</td>\n",
       "      <td>2038.969971</td>\n",
       "      <td>3.520860e+09</td>\n",
       "      <td>2038.969971</td>\n",
       "      <td>18222.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>519</th>\n",
       "      <td>2042.199951</td>\n",
       "      <td>2064.729980</td>\n",
       "      <td>2042.199951</td>\n",
       "      <td>2064.290039</td>\n",
       "      <td>3.484090e+09</td>\n",
       "      <td>2064.290039</td>\n",
       "      <td>18222.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>520</th>\n",
       "      <td>2063.520020</td>\n",
       "      <td>2067.360107</td>\n",
       "      <td>2058.729980</td>\n",
       "      <td>2060.989990</td>\n",
       "      <td>1.411860e+09</td>\n",
       "      <td>2060.989990</td>\n",
       "      <td>18222.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>521</th>\n",
       "      <td>2057.770020</td>\n",
       "      <td>2057.770020</td>\n",
       "      <td>2044.199951</td>\n",
       "      <td>2056.500000</td>\n",
       "      <td>2.492510e+09</td>\n",
       "      <td>2056.500000</td>\n",
       "      <td>18222.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>522</th>\n",
       "      <td>2060.540039</td>\n",
       "      <td>2081.560059</td>\n",
       "      <td>2060.540039</td>\n",
       "      <td>2078.360107</td>\n",
       "      <td>2.542000e+09</td>\n",
       "      <td>2078.360107</td>\n",
       "      <td>18222.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>523</th>\n",
       "      <td>2077.340088</td>\n",
       "      <td>2077.340088</td>\n",
       "      <td>2061.969971</td>\n",
       "      <td>2063.360107</td>\n",
       "      <td>2.367430e+09</td>\n",
       "      <td>2063.360107</td>\n",
       "      <td>18222.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>524</th>\n",
       "      <td>2060.590088</td>\n",
       "      <td>2062.540039</td>\n",
       "      <td>2043.619995</td>\n",
       "      <td>2043.939941</td>\n",
       "      <td>2.655330e+09</td>\n",
       "      <td>2043.939941</td>\n",
       "      <td>18222.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>525</th>\n",
       "      <td>2060.590088</td>\n",
       "      <td>2062.540039</td>\n",
       "      <td>2043.619995</td>\n",
       "      <td>2043.939941</td>\n",
       "      <td>2.655330e+09</td>\n",
       "      <td>2043.939941</td>\n",
       "      <td>18281.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>526</th>\n",
       "      <td>2060.590088</td>\n",
       "      <td>2062.540039</td>\n",
       "      <td>2043.619995</td>\n",
       "      <td>2043.939941</td>\n",
       "      <td>2.655330e+09</td>\n",
       "      <td>2043.939941</td>\n",
       "      <td>18436.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>527 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Open         High          Low        Close        Volume  \\\n",
       "0            NaN          NaN          NaN          NaN           NaN   \n",
       "1            NaN          NaN          NaN          NaN           NaN   \n",
       "2            NaN          NaN          NaN          NaN           NaN   \n",
       "3            NaN          NaN          NaN          NaN           NaN   \n",
       "4            NaN          NaN          NaN          NaN           NaN   \n",
       "5            NaN          NaN          NaN          NaN           NaN   \n",
       "6            NaN          NaN          NaN          NaN           NaN   \n",
       "7            NaN          NaN          NaN          NaN           NaN   \n",
       "8            NaN          NaN          NaN          NaN           NaN   \n",
       "9            NaN          NaN          NaN          NaN           NaN   \n",
       "10           NaN          NaN          NaN          NaN           NaN   \n",
       "11           NaN          NaN          NaN          NaN           NaN   \n",
       "12           NaN          NaN          NaN          NaN           NaN   \n",
       "13           NaN          NaN          NaN          NaN           NaN   \n",
       "14           NaN          NaN          NaN          NaN           NaN   \n",
       "15           NaN          NaN          NaN          NaN           NaN   \n",
       "16           NaN          NaN          NaN          NaN           NaN   \n",
       "17           NaN          NaN          NaN          NaN           NaN   \n",
       "18           NaN          NaN          NaN          NaN           NaN   \n",
       "19           NaN          NaN          NaN          NaN           NaN   \n",
       "20           NaN          NaN          NaN          NaN           NaN   \n",
       "21           NaN          NaN          NaN          NaN           NaN   \n",
       "22           NaN          NaN          NaN          NaN           NaN   \n",
       "23           NaN          NaN          NaN          NaN           NaN   \n",
       "24           NaN          NaN          NaN          NaN           NaN   \n",
       "25           NaN          NaN          NaN          NaN           NaN   \n",
       "26           NaN          NaN          NaN          NaN           NaN   \n",
       "27           NaN          NaN          NaN          NaN           NaN   \n",
       "28           NaN          NaN          NaN          NaN           NaN   \n",
       "29           NaN          NaN          NaN          NaN           NaN   \n",
       "..           ...          ...          ...          ...           ...   \n",
       "497  2082.820068  2097.060059  2082.820068  2089.169922  3.929600e+09   \n",
       "498  2089.409912  2095.610107  2081.389893  2086.590088  3.587980e+09   \n",
       "499  2084.419922  2094.120117  2070.290039  2089.139893  3.884930e+09   \n",
       "500  2089.300049  2093.000000  2086.300049  2088.870117  2.852940e+09   \n",
       "501  2088.820068  2093.290039  2084.129883  2090.110107  1.466840e+09   \n",
       "502  2090.949951  2093.810059  2080.409912  2080.409912  4.245030e+09   \n",
       "503  2082.929932  2103.370117  2082.929932  2102.629883  3.712120e+09   \n",
       "504  2101.709961  2104.270020  2077.110107  2079.510010  3.950640e+09   \n",
       "505  2080.709961  2085.000000  2042.349976  2049.620117  4.306490e+09   \n",
       "506  2051.239990  2093.840088  2051.239990  2091.689941  4.214910e+09   \n",
       "507  2090.419922  2090.419922  2066.780029  2077.070068  4.043820e+09   \n",
       "508  2073.389893  2073.850098  2052.320068  2063.590088  4.173570e+09   \n",
       "509  2061.169922  2080.330078  2036.530029  2047.619995  4.385250e+09   \n",
       "510  2047.930054  2067.649902  2045.670044  2052.229980  3.715150e+09   \n",
       "511  2047.270020  2047.270020  2008.800049  2012.369995  4.301060e+09   \n",
       "512  2013.369995  2022.920044  1993.260010  2021.939941  4.612440e+09   \n",
       "513  2025.550049  2053.870117  2025.550049  2043.410034  4.353540e+09   \n",
       "514  2046.500000  2076.719971  2042.430054  2073.070068  4.635450e+09   \n",
       "515  2073.760010  2076.370117  2041.660034  2041.890015  4.327390e+09   \n",
       "516  2040.810059  2040.810059  2005.329956  2005.550049  6.683070e+09   \n",
       "517  2010.270020  2022.900024  2005.930054  2021.150024  3.760280e+09   \n",
       "518  2023.150024  2042.739990  2020.489990  2038.969971  3.520860e+09   \n",
       "519  2042.199951  2064.729980  2042.199951  2064.290039  3.484090e+09   \n",
       "520  2063.520020  2067.360107  2058.729980  2060.989990  1.411860e+09   \n",
       "521  2057.770020  2057.770020  2044.199951  2056.500000  2.492510e+09   \n",
       "522  2060.540039  2081.560059  2060.540039  2078.360107  2.542000e+09   \n",
       "523  2077.340088  2077.340088  2061.969971  2063.360107  2.367430e+09   \n",
       "524  2060.590088  2062.540039  2043.619995  2043.939941  2.655330e+09   \n",
       "525  2060.590088  2062.540039  2043.619995  2043.939941  2.655330e+09   \n",
       "526  2060.590088  2062.540039  2043.619995  2043.939941  2.655330e+09   \n",
       "\n",
       "       Adj Close    VALUE  \n",
       "0            NaN    243.1  \n",
       "1            NaN    246.3  \n",
       "2            NaN    250.1  \n",
       "3            NaN    260.3  \n",
       "4            NaN    266.2  \n",
       "5            NaN    272.9  \n",
       "6            NaN    279.5  \n",
       "7            NaN    280.7  \n",
       "8            NaN    275.4  \n",
       "9            NaN    271.7  \n",
       "10           NaN    273.3  \n",
       "11           NaN    271.0  \n",
       "12           NaN    281.2  \n",
       "13           NaN    290.7  \n",
       "14           NaN    308.5  \n",
       "15           NaN    320.3  \n",
       "16           NaN    336.4  \n",
       "17           NaN    344.5  \n",
       "18           NaN    351.8  \n",
       "19           NaN    356.6  \n",
       "20           NaN    360.2  \n",
       "21           NaN    361.4  \n",
       "22           NaN    368.1  \n",
       "23           NaN    381.2  \n",
       "24           NaN    388.5  \n",
       "25           NaN    392.3  \n",
       "26           NaN    391.7  \n",
       "27           NaN    386.5  \n",
       "28           NaN    385.9  \n",
       "29           NaN    386.7  \n",
       "..           ...      ...  \n",
       "497  2089.169922  18222.8  \n",
       "498  2086.590088  18222.8  \n",
       "499  2089.139893  18222.8  \n",
       "500  2088.870117  18222.8  \n",
       "501  2090.110107  18222.8  \n",
       "502  2080.409912  18222.8  \n",
       "503  2102.629883  18222.8  \n",
       "504  2079.510010  18222.8  \n",
       "505  2049.620117  18222.8  \n",
       "506  2091.689941  18222.8  \n",
       "507  2077.070068  18222.8  \n",
       "508  2063.590088  18222.8  \n",
       "509  2047.619995  18222.8  \n",
       "510  2052.229980  18222.8  \n",
       "511  2012.369995  18222.8  \n",
       "512  2021.939941  18222.8  \n",
       "513  2043.410034  18222.8  \n",
       "514  2073.070068  18222.8  \n",
       "515  2041.890015  18222.8  \n",
       "516  2005.550049  18222.8  \n",
       "517  2021.150024  18222.8  \n",
       "518  2038.969971  18222.8  \n",
       "519  2064.290039  18222.8  \n",
       "520  2060.989990  18222.8  \n",
       "521  2056.500000  18222.8  \n",
       "522  2078.360107  18222.8  \n",
       "523  2063.360107  18222.8  \n",
       "524  2043.939941  18222.8  \n",
       "525  2043.939941  18281.6  \n",
       "526  2043.939941  18436.5  \n",
       "\n",
       "[527 rows x 7 columns]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#vídeo\n",
    "#Ordered merges\n",
    "\n",
    "hardware = pd.read_csv(data_folder + \"feb-sales-Hardware.csv\", parse_dates=['Date'])\n",
    "service = pd.read_csv(data_folder + \"feb-sales-Service.csv\", parse_dates=['Date'])\n",
    "software = pd.read_csv(data_folder + \"feb-sales-Software.csv\", parse_dates=['Date'])\n",
    "software.sort_values('Date')\n",
    "hardware.sort_values('Date')\n",
    "\n",
    "pd.merge(hardware, software)   # Empty DataFrame  --- inner by default\n",
    "\n",
    "pd.merge(hardware, software, how='outer')         # Using merge(how=‘outer’)\n",
    "\n",
    "# pd.merge(hardware, software, how='outer').sorted_values('Date')    #não dá\n",
    "\n",
    "pd.merge_ordered(hardware, software)         # -----> Using merge_ordered()\n",
    "\n",
    "pd.merge_ordered(hardware, software, on=['Date', 'Company'], suffixes=['_hardware', '_software']).head()   #Using on & suffixes\n",
    "\n",
    "\n",
    "# Stocks and GDP data\n",
    "\n",
    "pd.merge_ordered(sp500, gdp_usa, left_on='Date', right_on='DATE')  # Ordered merge\n",
    "\n",
    "pd.merge_ordered(sp500, gdp_usa, left_on='Date', right_on='DATE', fill_method='ffill')   # Ordered merge with ffill"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercício 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         date ratings\n",
      "0  2016-01-01  Cloudy\n",
      "1  2016-01-04   Rainy\n",
      "2  2016-01-17   Sunny\n",
      "3  2016-02-08  Cloudy\n",
      "4  2016-03-01   Rainy\n",
      "=========================================================\n",
      "         date ratings_aus ratings_hous\n",
      "0  2016-01-01      Cloudy       Cloudy\n",
      "1  2016-01-04         NaN        Rainy\n",
      "2  2016-01-17       Sunny          NaN\n",
      "3  2016-02-08      Cloudy          NaN\n",
      "4  2016-03-01         NaN        Rainy\n",
      "=========================================================\n",
      "         date ratings_aus ratings_hous\n",
      "0  2016-01-01      Cloudy       Cloudy\n",
      "1  2016-01-04      Cloudy        Rainy\n",
      "2  2016-01-17       Sunny        Rainy\n",
      "3  2016-02-08      Cloudy        Rainy\n",
      "4  2016-03-01      Cloudy        Rainy\n"
     ]
    }
   ],
   "source": [
    "# Using merge_ordered()\n",
    "\n",
    "austin = pd.DataFrame({'date':['2016-01-01', '2016-02-08', '2016-01-17'], 'ratings':['Cloudy', 'Cloudy', 'Sunny']})\n",
    "houston = pd.DataFrame({'date':['2016-01-04', '2016-01-01', '2016-03-01'], 'ratings':['Rainy', 'Cloudy', 'Rainy']})\n",
    "\n",
    "# Perform the first ordered merge: tx_weather\n",
    "tx_weather = pd.merge_ordered(austin, houston)\n",
    "\n",
    "print(tx_weather)\n",
    "print(\"=========================================================\")\n",
    "\n",
    "# Perform the second ordered merge: tx_weather_suff\n",
    "tx_weather_suff = pd.merge_ordered(austin, houston, on='date', suffixes=['_aus', '_hous'])\n",
    "\n",
    "print(tx_weather_suff)\n",
    "print(\"=========================================================\")\n",
    "\n",
    "# Perform the third ordered merge: tx_weather_ffill\n",
    "tx_weather_ffill = pd.merge_ordered(austin, houston, on='date', suffixes=['_aus', '_hous'], fill_method='ffill')\n",
    "\n",
    "print(tx_weather_ffill)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercício 13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                  mpg  Price\n",
      "Date                        \n",
      "1970-12-31  17.689655   3.35\n",
      "1971-12-31  21.111111   3.56\n",
      "1972-12-31  18.714286   3.56\n",
      "1973-12-31  17.100000   3.56\n",
      "1974-12-31  22.769231  10.11\n",
      "1975-12-31  20.266667  11.16\n",
      "1976-12-31  21.573529  11.16\n",
      "1977-12-31  23.375000  13.90\n",
      "1978-12-31  24.061111  14.85\n",
      "1979-12-31  25.093103  14.85\n",
      "1980-12-31  33.803704  32.50\n",
      "1981-12-31  30.185714  38.00\n",
      "1982-12-31  32.000000  33.85\n",
      "            mpg     Price\n",
      "mpg    1.000000  0.948677\n",
      "Price  0.948677  1.000000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mpg</th>\n",
       "      <th>cyl</th>\n",
       "      <th>displ</th>\n",
       "      <th>hp</th>\n",
       "      <th>weight</th>\n",
       "      <th>accel</th>\n",
       "      <th>yr</th>\n",
       "      <th>origin</th>\n",
       "      <th>name</th>\n",
       "      <th>Date</th>\n",
       "      <th>Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>387</th>\n",
       "      <td>27.0</td>\n",
       "      <td>4</td>\n",
       "      <td>140.0</td>\n",
       "      <td>86</td>\n",
       "      <td>2790</td>\n",
       "      <td>15.6</td>\n",
       "      <td>1982-01-01</td>\n",
       "      <td>US</td>\n",
       "      <td>ford mustang gl</td>\n",
       "      <td>1982-01-01</td>\n",
       "      <td>33.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>388</th>\n",
       "      <td>44.0</td>\n",
       "      <td>4</td>\n",
       "      <td>97.0</td>\n",
       "      <td>52</td>\n",
       "      <td>2130</td>\n",
       "      <td>24.6</td>\n",
       "      <td>1982-01-01</td>\n",
       "      <td>Europe</td>\n",
       "      <td>vw pickup</td>\n",
       "      <td>1982-01-01</td>\n",
       "      <td>33.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>389</th>\n",
       "      <td>32.0</td>\n",
       "      <td>4</td>\n",
       "      <td>135.0</td>\n",
       "      <td>84</td>\n",
       "      <td>2295</td>\n",
       "      <td>11.6</td>\n",
       "      <td>1982-01-01</td>\n",
       "      <td>US</td>\n",
       "      <td>dodge rampage</td>\n",
       "      <td>1982-01-01</td>\n",
       "      <td>33.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>390</th>\n",
       "      <td>28.0</td>\n",
       "      <td>4</td>\n",
       "      <td>120.0</td>\n",
       "      <td>79</td>\n",
       "      <td>2625</td>\n",
       "      <td>18.6</td>\n",
       "      <td>1982-01-01</td>\n",
       "      <td>US</td>\n",
       "      <td>ford ranger</td>\n",
       "      <td>1982-01-01</td>\n",
       "      <td>33.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>391</th>\n",
       "      <td>31.0</td>\n",
       "      <td>4</td>\n",
       "      <td>119.0</td>\n",
       "      <td>82</td>\n",
       "      <td>2720</td>\n",
       "      <td>19.4</td>\n",
       "      <td>1982-01-01</td>\n",
       "      <td>US</td>\n",
       "      <td>chevy s-10</td>\n",
       "      <td>1982-01-01</td>\n",
       "      <td>33.85</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      mpg  cyl  displ  hp  weight  accel         yr  origin             name  \\\n",
       "387  27.0    4  140.0  86    2790   15.6 1982-01-01      US  ford mustang gl   \n",
       "388  44.0    4   97.0  52    2130   24.6 1982-01-01  Europe        vw pickup   \n",
       "389  32.0    4  135.0  84    2295   11.6 1982-01-01      US    dodge rampage   \n",
       "390  28.0    4  120.0  79    2625   18.6 1982-01-01      US      ford ranger   \n",
       "391  31.0    4  119.0  82    2720   19.4 1982-01-01      US       chevy s-10   \n",
       "\n",
       "          Date  Price  \n",
       "387 1982-01-01  33.85  \n",
       "388 1982-01-01  33.85  \n",
       "389 1982-01-01  33.85  \n",
       "390 1982-01-01  33.85  \n",
       "391 1982-01-01  33.85  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using merge_asof()\n",
    "\n",
    "# Similar to pd.merge_ordered(), the pd.merge_asof() function will also merge values in order using the on column, \n",
    "# but for each row in the left DataFrame, only rows from the right DataFrame whose 'on' column values are less than \n",
    "# the left value will be kept.\n",
    "#This function can be used to align disparate datetime frequencies without having to first resample.\n",
    "\n",
    "auto = pd.read_csv(data_folder + \"automobiles.csv\", parse_dates=['yr'])\n",
    "oil = pd.read_csv(data_folder + \"oil_price.csv\", parse_dates=['Date'])\n",
    "\n",
    "\n",
    "# Merge auto and oil: merged\n",
    "merged = pd.merge_asof(auto, oil, left_on='yr', right_on='Date')\n",
    "# Print the tail of merged  --- ver abaixo\n",
    "\n",
    "\n",
    "# Resample merged: yearly\n",
    "yearly = merged.resample('A', on='Date')[['mpg', 'Price']].mean()\n",
    "\n",
    "# Print yearly\n",
    "print(yearly)\n",
    "\n",
    "# print yearly.corr()\n",
    "print(yearly.corr())\n",
    "\n",
    "\n",
    "merged.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 4 - Case Study: Summer Olympics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercício 1 - Medals in the Summer Olympics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vídeo\n",
    "#Medals in the Summer Olympics\n",
    "\n",
    "# Does a host country win more medals?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercício 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Edition  Grand Total       City         Country\n",
      "0     1896          151     Athens          Greece\n",
      "1     1900          512      Paris          France\n",
      "2     1904          470  St. Louis   United States\n",
      "3     1908          804     London  United Kingdom\n",
      "4     1912          885  Stockholm          Sweden\n"
     ]
    }
   ],
   "source": [
    "# Create file path: file_path\n",
    "file_path = data_folder + \"Summer Olympic medalists 1896 to 2008 - EDITIONS.tsv\"\n",
    "\n",
    "# Load DataFrame from file_path: editions\n",
    "editions = pd.read_csv(file_path, sep='\\t')\n",
    "\n",
    "# Extract the relevant columns: editions\n",
    "editions = editions[['Edition', 'Grand Total', 'City', 'Country']]\n",
    "\n",
    "# Print editions DataFrame\n",
    "print(editions.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercício 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             Country  NOC\n",
      "197  Virgin Islands*  ISV\n",
      "198            Yemen  YEM\n",
      "199           Zambia  ZAM\n",
      "200         Zimbabwe  ZIM\n"
     ]
    }
   ],
   "source": [
    "# Create the file path: file_path\n",
    "file_path = data_folder + \"Summer Olympic medalists 1896 to 2008 - IOC COUNTRY CODES.csv\"\n",
    "\n",
    "# Load DataFrame from file_path: ioc_codes\n",
    "ioc_codes = pd.read_csv(file_path)\n",
    "\n",
    "# Extract the relevant columns: ioc_codes\n",
    "ioc_codes = ioc_codes[['Country', 'NOC']]\n",
    "\n",
    "# Print first and last 5 rows of ioc_codes\n",
    "print(ioc_codes.tail(4))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercício 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>City</th>\n",
       "      <th>Edition</th>\n",
       "      <th>Sport</th>\n",
       "      <th>Discipline</th>\n",
       "      <th>Athlete</th>\n",
       "      <th>NOC</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Event</th>\n",
       "      <th>Event_gender</th>\n",
       "      <th>Medal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Athens</td>\n",
       "      <td>1896</td>\n",
       "      <td>Aquatics</td>\n",
       "      <td>Swimming</td>\n",
       "      <td>HAJOS, Alfred</td>\n",
       "      <td>HUN</td>\n",
       "      <td>Men</td>\n",
       "      <td>100m freestyle</td>\n",
       "      <td>M</td>\n",
       "      <td>Gold</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Athens</td>\n",
       "      <td>1896</td>\n",
       "      <td>Aquatics</td>\n",
       "      <td>Swimming</td>\n",
       "      <td>HERSCHMANN, Otto</td>\n",
       "      <td>AUT</td>\n",
       "      <td>Men</td>\n",
       "      <td>100m freestyle</td>\n",
       "      <td>M</td>\n",
       "      <td>Silver</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Athens</td>\n",
       "      <td>1896</td>\n",
       "      <td>Aquatics</td>\n",
       "      <td>Swimming</td>\n",
       "      <td>DRIVAS, Dimitrios</td>\n",
       "      <td>GRE</td>\n",
       "      <td>Men</td>\n",
       "      <td>100m freestyle for sailors</td>\n",
       "      <td>M</td>\n",
       "      <td>Bronze</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Athens</td>\n",
       "      <td>1896</td>\n",
       "      <td>Aquatics</td>\n",
       "      <td>Swimming</td>\n",
       "      <td>MALOKINIS, Ioannis</td>\n",
       "      <td>GRE</td>\n",
       "      <td>Men</td>\n",
       "      <td>100m freestyle for sailors</td>\n",
       "      <td>M</td>\n",
       "      <td>Gold</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Athens</td>\n",
       "      <td>1896</td>\n",
       "      <td>Aquatics</td>\n",
       "      <td>Swimming</td>\n",
       "      <td>CHASAPIS, Spiridon</td>\n",
       "      <td>GRE</td>\n",
       "      <td>Men</td>\n",
       "      <td>100m freestyle for sailors</td>\n",
       "      <td>M</td>\n",
       "      <td>Silver</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     City  Edition     Sport Discipline             Athlete  NOC Gender  \\\n",
       "0  Athens     1896  Aquatics   Swimming       HAJOS, Alfred  HUN    Men   \n",
       "1  Athens     1896  Aquatics   Swimming    HERSCHMANN, Otto  AUT    Men   \n",
       "2  Athens     1896  Aquatics   Swimming   DRIVAS, Dimitrios  GRE    Men   \n",
       "3  Athens     1896  Aquatics   Swimming  MALOKINIS, Ioannis  GRE    Men   \n",
       "4  Athens     1896  Aquatics   Swimming  CHASAPIS, Spiridon  GRE    Men   \n",
       "\n",
       "                        Event Event_gender   Medal  \n",
       "0              100m freestyle            M    Gold  \n",
       "1              100m freestyle            M  Silver  \n",
       "2  100m freestyle for sailors            M  Bronze  \n",
       "3  100m freestyle for sailors            M    Gold  \n",
       "4  100m freestyle for sailors            M  Silver  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Building medals DataFrame\n",
    "\n",
    "#ERA PRECISO \n",
    "#You have a sequence of files summer_1896.csv, summer_1900.csv, ..., summer_2008.csv, one for each Olympic edition (year).\n",
    "\n",
    "# medals_dict = {}\n",
    "\n",
    "# for year in editions['Edition']:\n",
    "\n",
    "#     file_path = \"C:/Users/Utilizador/Dropbox/Python/ficheiros/DataCamp/DataCamp - Merging DataFrames with pandas/Summer Olympic medals/summer_{:d}.csv\".format(year)\n",
    "    \n",
    "#     medals_dict[year] = pd.read_csv(file_path)\n",
    "    \n",
    "#     # Select only the columns 'Athlete', 'NOC', and 'Medal' from medals_dict[year].\n",
    "#     medals_dict[year] = medals_dict[year][['Athlete', 'NOC', 'Medal']]\n",
    "    \n",
    "#     # Assign year to column 'Edition' of medals_dict\n",
    "#     medals_dict[year]['Edition'] = year\n",
    "    \n",
    "# # Concatenate medals_dict: medals\n",
    "# medals = pd.concat(medals_dict, ignore_index=True)\n",
    "\n",
    "# # Print first and last 5 rows of medals\n",
    "# print(medals.head())\n",
    "\n",
    "medals = pd.read_excel(data_folder + \"Summer Olympic medalists 1896 to 2008 - ALL MEDALISTS - Cópia.xlsx\")\n",
    "\n",
    "medals.head(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercício 5 - Quantifying performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vídeo\n",
    "#Quantifying performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercício 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOC      AFG  AHO  ALG   ANZ  ARG  ARM  AUS  AUT  AZE  BAH  BAR  BDI\n",
      "Edition                                                             \n",
      "1896     NaN  NaN  NaN   NaN  NaN  NaN  2.0  5.0  NaN  NaN  NaN  NaN\n",
      "1900     NaN  NaN  NaN   NaN  NaN  NaN  5.0  6.0  NaN  NaN  NaN  NaN\n",
      "1904     NaN  NaN  NaN   NaN  NaN  NaN  NaN  1.0  NaN  NaN  NaN  NaN\n",
      "1908     NaN  NaN  NaN  19.0  NaN  NaN  NaN  1.0  NaN  NaN  NaN  NaN\n",
      "============estes países não ganharam muitas medalhas=============================\n",
      "NOC      AFG  AHO  ALG  ANZ   ARG  ARM    AUS  AUT  AZE  BAH  BAR  BDI\n",
      "Edition                                                               \n",
      "1996     NaN  NaN  3.0  NaN  20.0  2.0  132.0  3.0  1.0  5.0  NaN  1.0\n",
      "2000     NaN  NaN  5.0  NaN  20.0  1.0  183.0  4.0  3.0  6.0  1.0  NaN\n",
      "2004     NaN  NaN  NaN  NaN  47.0  NaN  157.0  8.0  5.0  2.0  NaN  NaN\n",
      "2008     1.0  NaN  2.0  NaN  51.0  6.0  149.0  3.0  7.0  5.0  NaN  NaN\n"
     ]
    }
   ],
   "source": [
    "# Counting medals by country/edition in a pivot table\n",
    "\n",
    "medals = medals[['Athlete', 'NOC', 'Medal', 'Edition']]   # só querem estas 4 colunas\n",
    "\n",
    "# Construct the pivot_table: medal_counts\n",
    "medal_counts = medals.pivot_table(index='Edition', columns='NOC', values='Athlete', aggfunc='count')  # nº de medalhas por país \n",
    "\n",
    "# Print the first & last 5 rows of medal_counts\n",
    "print(medal_counts.iloc[0:4, 0:12])\n",
    "print(\"============estes países não ganharam muitas medalhas=============================\")\n",
    "print(medal_counts.iloc[-4:, 0:12])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercício 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOC      AFG  AHO  ALG   ANZ  ARG  ARM   AUS   AUT  AZE  BAH  BAR  BDI\n",
      "Edition                                                               \n",
      "1896     NaN  NaN  NaN   NaN  NaN  NaN  0.01  0.03  NaN  NaN  NaN  NaN\n",
      "1900     NaN  NaN  NaN   NaN  NaN  NaN  0.01  0.01  NaN  NaN  NaN  NaN\n",
      "1904     NaN  NaN  NaN   NaN  NaN  NaN   NaN  0.00  NaN  NaN  NaN  NaN\n",
      "1908     NaN  NaN  NaN  0.02  NaN  NaN   NaN  0.00  NaN  NaN  NaN  NaN\n",
      "1912     NaN  NaN  NaN  0.01  NaN  NaN   NaN  0.02  NaN  NaN  NaN  NaN\n",
      "==============================================\n",
      "NOC      UGA   UKR  URS  URU   USA  UZB  VEN  VIE   YUG  ZAM  ZIM  ZZX\n",
      "Edition                                                               \n",
      "1992     NaN   NaN  NaN  NaN  0.13  NaN  NaN  NaN   NaN  NaN  NaN  NaN\n",
      "1996     0.0  0.02  NaN  NaN  0.14  0.0  NaN  NaN  0.01  0.0  NaN  NaN\n",
      "2000     NaN  0.02  NaN  0.0  0.12  0.0  NaN  0.0  0.01  NaN  NaN  NaN\n",
      "2004     NaN  0.02  NaN  NaN  0.13  0.0  0.0  NaN   NaN  NaN  0.0  NaN\n",
      "2008     NaN  0.02  NaN  NaN  0.15  0.0  0.0  0.0   NaN  NaN  0.0  NaN\n"
     ]
    }
   ],
   "source": [
    "# Computing fraction of medals per Olympic edition\n",
    "\n",
    "# Set Index of editions to be 'Edition': totals\n",
    "totals = editions.set_index('Edition')\n",
    "\n",
    "# Reassign totals['Grand Total']: totals\n",
    "totals = totals['Grand Total']\n",
    "\n",
    "# Divide medal_counts by totals: fractions\n",
    "fractions = round(medal_counts.divide(totals, axis='rows'), 2)\n",
    "\n",
    "# Print first & last 5 rows of fractions\n",
    "print(fractions.iloc[0:5, 0:12])\n",
    "print(\"==============================================\")\n",
    "print(fractions.iloc[-5:, -12:])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercício 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NOC  Edition  AFG  AHO  ALG   ANZ  ARG  ARM  AUS    AUT  AZE  BAH  BAR\n",
      "0       1896  NaN  NaN  NaN   NaN  NaN  NaN  NaN    NaN  NaN  NaN  NaN\n",
      "1       1900  NaN  NaN  NaN   NaN  NaN  NaN  0.0 -33.33  NaN  NaN  NaN\n",
      "2       1904  NaN  NaN  NaN   NaN  NaN  NaN  0.0 -33.33  NaN  NaN  NaN\n",
      "3       1908  NaN  NaN  NaN   NaN  NaN  NaN  0.0 -25.00  NaN  NaN  NaN\n",
      "4       1912  NaN  NaN  NaN -25.0  NaN  NaN  0.0  20.00  NaN  NaN  NaN\n",
      "===============================================================================\n",
      "NOC  Edition  AFG  AHO  ALG  ANZ   ARG  ARM    AUS   AUT  AZE  BAH  BAR\n",
      "21      1992  NaN  NaN  NaN  0.0 -7.69  NaN   2.02 -5.00  NaN  NaN  NaN\n",
      "22      1996  NaN  NaN  NaN  0.0  1.30  NaN  10.83 -4.76  NaN  NaN  NaN\n",
      "23      2000  NaN  NaN  NaN  0.0  1.11  NaN  12.73 -4.55  NaN  NaN  NaN\n",
      "24      2004  NaN  NaN  NaN  0.0  8.17  NaN   8.62 -4.35  NaN  NaN  NaN\n",
      "25      2008  NaN  NaN  NaN  0.0  6.67  NaN   5.80 -4.17  NaN  NaN  NaN\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>NOC</th>\n",
       "      <th>Edition</th>\n",
       "      <th>AFG</th>\n",
       "      <th>AHO</th>\n",
       "      <th>ALG</th>\n",
       "      <th>ANZ</th>\n",
       "      <th>ARG</th>\n",
       "      <th>ARM</th>\n",
       "      <th>AUS</th>\n",
       "      <th>AUT</th>\n",
       "      <th>AZE</th>\n",
       "      <th>...</th>\n",
       "      <th>URS</th>\n",
       "      <th>URU</th>\n",
       "      <th>USA</th>\n",
       "      <th>UZB</th>\n",
       "      <th>VEN</th>\n",
       "      <th>VIE</th>\n",
       "      <th>YUG</th>\n",
       "      <th>ZAM</th>\n",
       "      <th>ZIM</th>\n",
       "      <th>ZZX</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1896</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1900</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-33.33</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-7.69</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>37.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1904</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-33.33</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>200.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-21.21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1908</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-25.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-19.44</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1912</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-25.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>20.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-12.41</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1920</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-33.33</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-6.82</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1924</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.50</td>\n",
       "      <td>-16.67</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1.01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1928</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>200.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.67</td>\n",
       "      <td>-0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25.00</td>\n",
       "      <td>-6.10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>inf</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1932</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-22.22</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.17</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-33.33</td>\n",
       "      <td>3.54</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1936</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-14.29</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-14.29</td>\n",
       "      <td>55.56</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-5.17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-33.330000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1948</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-10.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>22.50</td>\n",
       "      <td>-10.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-25.00</td>\n",
       "      <td>-1.52</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1952</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-7.41</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.29</td>\n",
       "      <td>-9.09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.00</td>\n",
       "      <td>-2.46</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1956</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-14.29</td>\n",
       "      <td>NaN</td>\n",
       "      <td>60.00</td>\n",
       "      <td>-8.33</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>23.08</td>\n",
       "      <td>-4.76</td>\n",
       "      <td>-2.87</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19.050000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1960</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-12.50</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13.64</td>\n",
       "      <td>-7.69</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>6.25</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-2.54</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.860000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1964</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-11.11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-14.29</td>\n",
       "      <td>-1.58</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-5.210000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1968</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-10.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.54</td>\n",
       "      <td>-7.14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1.18</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-1.72</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.400000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1972</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-9.09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.74</td>\n",
       "      <td>-6.67</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-1.86</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.250000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1976</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.65</td>\n",
       "      <td>-6.25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>3.85</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-1.98</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-4.040000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1980</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-3.41</td>\n",
       "      <td>-5.88</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>9.72</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.960000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1984</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.42</td>\n",
       "      <td>-5.56</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.36</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16.390000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1988</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.83</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.45</td>\n",
       "      <td>-5.26</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.42</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-1.76</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.670000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1992</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-7.69</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.02</td>\n",
       "      <td>-5.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-1.36</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1996</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.30</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.83</td>\n",
       "      <td>-4.76</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-3.840000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12.73</td>\n",
       "      <td>-4.55</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-12.50</td>\n",
       "      <td>-1.41</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-3.490000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2004</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.62</td>\n",
       "      <td>-4.35</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-1.08</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-50.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2008</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.67</td>\n",
       "      <td>NaN</td>\n",
       "      <td>5.80</td>\n",
       "      <td>-4.17</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>-0.54</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-33.33</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>26 rows × 139 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "NOC  Edition  AFG  AHO  ALG   ANZ     ARG  ARM    AUS    AUT  AZE  ...    \\\n",
       "0       1896  NaN  NaN  NaN   NaN     NaN  NaN    NaN    NaN  NaN  ...     \n",
       "1       1900  NaN  NaN  NaN   NaN     NaN  NaN   0.00 -33.33  NaN  ...     \n",
       "2       1904  NaN  NaN  NaN   NaN     NaN  NaN   0.00 -33.33  NaN  ...     \n",
       "3       1908  NaN  NaN  NaN   NaN     NaN  NaN   0.00 -25.00  NaN  ...     \n",
       "4       1912  NaN  NaN  NaN -25.0     NaN  NaN   0.00  20.00  NaN  ...     \n",
       "5       1920  NaN  NaN  NaN   0.0     NaN  NaN -33.33   0.00  NaN  ...     \n",
       "6       1924  NaN  NaN  NaN   0.0     NaN  NaN  12.50 -16.67  NaN  ...     \n",
       "7       1928  NaN  NaN  NaN   0.0  200.00  NaN   6.67  -0.00  NaN  ...     \n",
       "8       1932  NaN  NaN  NaN   0.0  -22.22  NaN   4.17   0.00  NaN  ...     \n",
       "9       1936  NaN  NaN  NaN   0.0  -14.29  NaN -14.29  55.56  NaN  ...     \n",
       "10      1948  NaN  NaN  NaN   0.0  -10.00  NaN  22.50 -10.00  NaN  ...     \n",
       "11      1952  NaN  NaN  NaN   0.0   -7.41  NaN  14.29  -9.09  NaN  ...     \n",
       "12      1956  NaN  NaN  NaN   0.0  -14.29  NaN  60.00  -8.33  NaN  ...     \n",
       "13      1960  NaN  NaN  NaN   0.0  -12.50  NaN  13.64  -7.69  NaN  ...     \n",
       "14      1964  NaN  NaN  NaN   0.0  -11.11  NaN  10.00   0.00  NaN  ...     \n",
       "15      1968  NaN  NaN  NaN   0.0  -10.00  NaN  11.54  -7.14  NaN  ...     \n",
       "16      1972  NaN  NaN  NaN   0.0   -9.09  NaN  -0.74  -6.67  NaN  ...     \n",
       "17      1976  NaN  NaN  NaN   0.0    0.00  NaN  -0.65  -6.25  NaN  ...     \n",
       "18      1980  NaN  NaN  NaN   0.0    0.00  NaN  -3.41  -5.88  NaN  ...     \n",
       "19      1984  NaN  NaN  NaN   0.0    0.00  NaN   2.42  -5.56  NaN  ...     \n",
       "20      1988  NaN  NaN  NaN   0.0    0.83  NaN  -0.45  -5.26  NaN  ...     \n",
       "21      1992  NaN  NaN  NaN   0.0   -7.69  NaN   2.02  -5.00  NaN  ...     \n",
       "22      1996  NaN  NaN  NaN   0.0    1.30  NaN  10.83  -4.76  NaN  ...     \n",
       "23      2000  NaN  NaN  NaN   0.0    1.11  NaN  12.73  -4.55  NaN  ...     \n",
       "24      2004  NaN  NaN  NaN   0.0    8.17  NaN   8.62  -4.35  NaN  ...     \n",
       "25      2008  NaN  NaN  NaN   0.0    6.67  NaN   5.80  -4.17  NaN  ...     \n",
       "\n",
       "NOC    URS    URU     USA  UZB  VEN  VIE        YUG  ZAM    ZIM    ZZX  \n",
       "0      NaN    NaN     NaN  NaN  NaN  NaN        NaN  NaN    NaN    NaN  \n",
       "1      NaN    NaN   -7.69  NaN  NaN  NaN        NaN  NaN    NaN  37.50  \n",
       "2      NaN    NaN  200.00  NaN  NaN  NaN        NaN  NaN    NaN -21.21  \n",
       "3      NaN    NaN  -19.44  NaN  NaN  NaN        NaN  NaN    NaN   0.00  \n",
       "4      NaN    NaN  -12.41  NaN  NaN  NaN        NaN  NaN    NaN   0.00  \n",
       "5      NaN    NaN   -6.82  NaN  NaN  NaN        NaN  NaN    NaN   0.00  \n",
       "6      NaN    NaN   -1.01  NaN  NaN  NaN        NaN  NaN    NaN   0.00  \n",
       "7      NaN  25.00   -6.10  NaN  NaN  NaN        inf  NaN    NaN   0.00  \n",
       "8      NaN -33.33    3.54  NaN  NaN  NaN   0.000000  NaN    NaN   0.00  \n",
       "9      NaN   0.00   -5.17  NaN  NaN  NaN -33.330000  NaN    NaN   0.00  \n",
       "10     NaN -25.00   -1.52  NaN  NaN  NaN  50.000000  NaN    NaN   0.00  \n",
       "11     NaN  12.00   -2.46  NaN  NaN  NaN  40.000000  NaN    NaN   0.00  \n",
       "12   23.08  -4.76   -2.87  NaN  NaN  NaN  19.050000  NaN    NaN   0.00  \n",
       "13    6.25   0.00   -2.54  NaN  NaN  NaN   2.860000  NaN    NaN   0.00  \n",
       "14    0.00 -14.29   -1.58  NaN  NaN  NaN  -5.210000  NaN    NaN   0.00  \n",
       "15    1.18   0.00   -1.72  NaN  NaN  NaN   9.400000  NaN    NaN   0.00  \n",
       "16    0.78   0.00   -1.86  NaN  NaN  NaN   1.250000  NaN    NaN   0.00  \n",
       "17    3.85   0.00   -1.98  NaN  NaN  NaN  -4.040000  NaN    NaN   0.00  \n",
       "18    9.72   0.00    0.00  NaN  NaN  NaN  10.960000  NaN    NaN   0.00  \n",
       "19    0.00   0.00    1.36  NaN  NaN  NaN  16.390000  NaN   0.00   0.00  \n",
       "20   -0.42   0.00   -1.76  NaN  NaN  NaN   5.670000  NaN   0.00   0.00  \n",
       "21    0.00   0.00   -1.36  NaN  NaN  NaN   0.000000  NaN   0.00   0.00  \n",
       "22    0.00   0.00   -1.00  NaN  NaN  NaN  -3.840000  NaN   0.00   0.00  \n",
       "23    0.00 -12.50   -1.41  NaN  NaN  NaN  -3.490000  NaN   0.00   0.00  \n",
       "24    0.00   0.00   -1.08  NaN  NaN  NaN   0.000000  NaN -50.00   0.00  \n",
       "25    0.00   0.00   -0.54  NaN  NaN  NaN   0.000000  NaN -33.33   0.00  \n",
       "\n",
       "[26 rows x 139 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Computing percentage change in fraction of medals won\n",
    "\n",
    "# ---> The expanding mean provides a way to see this down each column. <---------------------------------- expanding()\n",
    "# ---> It is the value of the mean with all the data available up to that point in time. \n",
    "\n",
    "# Apply the expanding mean: mean_fractions\n",
    "mean_fractions = fractions.expanding().mean()\n",
    "\n",
    "# Compute the percentage change: fractions_change\n",
    "fractions_change = round(mean_fractions.pct_change() * 100, 2)\n",
    "\n",
    "# Reset the index of fractions_change: fractions_change\n",
    "fractions_change = fractions_change.reset_index()\n",
    "\n",
    "# Print first & last 5 rows of fractions_change\n",
    "print(fractions_change.iloc[0:5, 0:12])\n",
    "print(\"===============================================================================\")\n",
    "print(fractions_change.iloc[-5:, 0:12])\n",
    "fractions_change"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exercício 9 - Reshaping and plotting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vídeo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercício 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         NOC\n",
      "Edition     \n",
      "1972     NaN\n",
      "1980     NaN\n",
      "1988     NaN\n",
      "    Edition  NOC\n",
      "0      1896  GRE\n",
      "1      1900  FRA\n",
      "2      1904  USA\n",
      "3      1908  GBR\n",
      "4      1912  SWE\n",
      "5      1920  BEL\n",
      "6      1924  FRA\n",
      "7      1928  NED\n",
      "8      1932  USA\n",
      "9      1936  GER\n",
      "10     1948  GBR\n",
      "11     1952  FIN\n",
      "12     1956  AUS\n",
      "13     1960  ITA\n",
      "14     1964  JPN\n",
      "15     1968  MEX\n",
      "16     1972  FRG\n",
      "17     1976  CAN\n",
      "18     1980  URS\n",
      "19     1984  USA\n",
      "20     1988  KOR\n",
      "21     1992  ESP\n",
      "22     1996  USA\n",
      "23     2000  AUS\n",
      "24     2004  GRE\n",
      "25     2008  CHN\n"
     ]
    }
   ],
   "source": [
    "# Building hosts DataFrame   \n",
    "#queremos um dataframe com edition e NOC -> merge editions e ioc_codes, preencher nulos (pôe e tirar index para isto)\n",
    "\n",
    "hosts = pd.merge(editions, ioc_codes, how='left')\n",
    "\n",
    "hosts = hosts[['Edition', 'NOC']].set_index('Edition')\n",
    "\n",
    "# Use the .loc[] accessor to find and assign the missing values to the 'NOC' column in hosts\n",
    "print(hosts.loc[hosts.NOC.isnull()])\n",
    "hosts.loc[1972, 'NOC'] = 'FRG'\n",
    "hosts.loc[1980, 'NOC'] = 'URS'\n",
    "hosts.loc[1988, 'NOC'] = 'KOR'\n",
    "\n",
    "# Reset Index of hosts: hosts\n",
    "hosts = hosts.reset_index()\n",
    "\n",
    "print(hosts)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercício 11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(26, 139)\n",
      "(3588, 3) (26, 139)\n",
      "     Edition  NOC  fractions Change\n",
      "567     1992  CHN              8.33\n",
      "568     1996  CHN              9.62\n",
      "569     2000  CHN             -3.16\n",
      "570     2004  CHN              1.45\n",
      "571     2008  CHN             13.27\n"
     ]
    }
   ],
   "source": [
    "# Reshaping fraction_change for analysis of China\n",
    "\n",
    "print(fractions_change.shape)   #(26, 139)\n",
    "\n",
    "# Reshape fractions_change: reshaped\n",
    "reshaped = pd.melt(fractions_change, id_vars='Edition', value_name='fractions Change')\n",
    "\n",
    "print(reshaped.shape, fractions_change.shape)\n",
    "\n",
    "chn = reshaped[reshaped['NOC'] == 'CHN']\n",
    "\n",
    "print(chn.tail())    #2008 foi em Pequim\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercício 12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Edition  NOC  fractions Change\n",
      "0     1956  AUS             60.00\n",
      "1     2000  AUS             12.73\n",
      "2     1920  BEL             50.00\n",
      "3     1976  CAN             -0.79\n",
      "4     2008  CHN             13.27\n",
      "=========================================================\n",
      "         NOC  fractions Change\n",
      "Edition                       \n",
      "1896     GRE               NaN\n",
      "1900     FRA            207.14\n",
      "1904     USA            200.00\n",
      "1908     GBR            136.25\n",
      "1912     SWE             77.78\n"
     ]
    }
   ],
   "source": [
    "# Merging to compute influence  ---> merge reshaped and hosts and tidy the result (p ver a influência do país organizador)\n",
    "\n",
    "merged = pd.merge(reshaped, hosts, how='inner')   #hosts já tinha os nulls preenchidos, reshaped tb(?)\n",
    "\n",
    "print(merged.head())\n",
    "print(\"=========================================================\")\n",
    "\n",
    "influence = merged.set_index('Edition').sort_index()\n",
    "\n",
    "print(influence.head())   # sim tem influência, nesta amostra pelo menos\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercício 13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plotting influence of host country\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "change = influence['fractions Change']\n",
    "\n",
    "graph = change.plot(kind='bar')\n",
    "\n",
    "# Customize the plot to improve readability\n",
    "graph.set_ylabel(\"% Change of Host Country Medal Count\")\n",
    "graph.set_title(\"Is there a Host Country Advantage?\")\n",
    "graph.set_xticklabels(editions['Country'])\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exercício 14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#vídeo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fim"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
